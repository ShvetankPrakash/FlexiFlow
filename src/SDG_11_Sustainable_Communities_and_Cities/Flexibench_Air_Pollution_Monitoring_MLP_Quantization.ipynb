{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **FlexiBench Air Pollution MLP Quantization**\n",
        "### Author: Shvetank Prakash\n",
        "### Date: Jan 2025\n",
        "#### Helpful links:\n",
        "\n",
        "[Co-Design of Approximate Multilayer Perceptron for Ultra-Resource Constrained Printed Circuits](https://arxiv.org/abs/2302.14576) (Paper Results Reproduced)\n",
        "\n",
        "[Gemmlowp Paper](https://arxiv.org/pdf/1712.05877)\n",
        "\n",
        "[Gemmlowp Implementation](https://github.com/google/gemmlowp/tree/master)\n"
      ],
      "metadata": {
        "id": "B6xKk1RMw3zG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Imports and Global Defs"
      ],
      "metadata": {
        "id": "zmARXYN5xetM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-model-optimization==0.8.0\n",
        "!pip install ucimlrepo==0.0.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-7RwFYPOH7xC",
        "outputId": "344a2278-3a7e-4367-f430-f5993c9612ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-model-optimization==0.8.0 in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization==0.8.0) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization==0.8.0) (0.1.9)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization==0.8.0) (1.26.4)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization==0.8.0) (1.17.0)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization==0.8.0) (25.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization==0.8.0) (1.17.2)\n",
            "Requirement already satisfied: ucimlrepo==0.0.7 in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo==0.0.7) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo==0.0.7) (2025.7.14)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo==0.0.7) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo==0.0.7) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo==0.0.7) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo==0.0.7) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo==0.0.7) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import math\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Setting environment variables\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8tYezt7xmzUa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Parameters\n",
        "INPUT_SIZE = 5\n",
        "HIDDEN_SIZE_1 = 20\n",
        "HIDDEN_SIZE_2 = 10\n",
        "OUTPUT_SIZE = 3\n",
        "\n",
        "# Training Parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE_TRAIN = 200\n",
        "BATCH_SIZE_TEST = 64\n",
        "LEARNING_RATE = 0.005\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "fMfZ9zYJIdCK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Read and Preprocess Dataset**"
      ],
      "metadata": {
        "id": "2Jml3fzQBpSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csv_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    labels = df.pop('label')\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((df.values.astype('float32') / 255., labels.values.astype('int32')))\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# Load in dataset from csv\n",
        "train_dataset = load_csv_data('training_data.csv')\n",
        "print(train_dataset)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(list(train_dataset)), seed=SEED)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE_TRAIN)\n",
        "\n",
        "test_dataset = load_csv_data('samples.csv')\n",
        "print(test_dataset)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE_TEST)"
      ],
      "metadata": {
        "id": "YJ_KJE3dn4kd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34bbd9e1-7959-44bd-a43a-58631317432f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_TensorSliceDataset element_spec=(TensorSpec(shape=(5,), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>\n",
            "<_TensorSliceDataset element_spec=(TensorSpec(shape=(5,), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Print a single element from each dataset\n",
        "# print(\"Single element from train_dataset:\")\n",
        "# for element in train_dataset.take(1):\n",
        "#     print(element)\n",
        "\n",
        "print(\"\\nSingle element from test_dataset:\")\n",
        "for element in test_dataset.take(1):\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cqoYwwI9JLVs",
        "outputId": "a9d3adf9-bcda-4bf1-9ac2-18f5c5ac8a23"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Single element from test_dataset:\n",
            "(<tf.Tensor: shape=(45, 5), dtype=float32, numpy=\n",
            "array([[0.47843137, 0.40784314, 0.47843137, 0.5058824 , 0.49803922],\n",
            "       [0.40392157, 0.57254905, 0.50980395, 0.5803922 , 0.3882353 ],\n",
            "       [0.47843137, 0.4627451 , 0.5372549 , 0.65882355, 0.49803922],\n",
            "       [0.36862746, 0.47843137, 0.5764706 , 0.5803922 , 0.27450982],\n",
            "       [0.40392157, 0.54509807, 0.4392157 , 0.6431373 , 0.5529412 ],\n",
            "       [0.25882354, 0.21568628, 0.16862746, 0.07058824, 0.        ],\n",
            "       [0.25882354, 0.18039216, 0.04705882, 0.20784314, 0.10980392],\n",
            "       [0.18431373, 0.2784314 , 0.27450982, 0.01568628, 0.05490196],\n",
            "       [0.03529412, 0.15294118, 0.04705882, 0.21960784, 0.16470589],\n",
            "       [0.14509805, 0.05098039, 0.1882353 , 0.17254902, 0.10980392],\n",
            "       [0.10980392, 0.31764707, 0.11764706, 0.10980392, 0.        ],\n",
            "       [0.        , 0.11764706, 0.03529412, 0.00392157, 0.16470589],\n",
            "       [0.14509805, 0.20784314, 0.29803923, 0.        , 0.10980392],\n",
            "       [1.        , 0.8509804 , 0.91764706, 0.8784314 , 0.8862745 ],\n",
            "       [0.8117647 , 0.90588236, 0.7490196 , 0.8235294 , 0.6666667 ],\n",
            "       [0.8862745 , 0.8235294 , 0.7882353 , 0.85490197, 0.7764706 ],\n",
            "       [0.9607843 , 0.9607843 , 0.78039217, 0.92156863, 0.8862745 ],\n",
            "       [0.        , 0.30588236, 0.08627451, 0.01568628, 0.10980392],\n",
            "       [0.5921569 , 1.        , 1.        , 1.        , 1.        ],\n",
            "       [0.7372549 , 0.9882353 , 0.7882353 , 0.8039216 , 0.72156864],\n",
            "       [1.        , 0.91764706, 0.7921569 , 0.98039216, 0.8862745 ],\n",
            "       [0.8117647 , 0.87058824, 0.7254902 , 0.95686275, 0.60784316],\n",
            "       [1.        , 0.9529412 , 0.7254902 , 0.9372549 , 0.83137256],\n",
            "       [0.9607843 , 0.93333334, 0.92156863, 0.827451  , 0.83137256],\n",
            "       [0.9254902 , 0.98039216, 0.93333334, 0.9411765 , 0.9411765 ],\n",
            "       [0.18431373, 0.10588235, 0.16470589, 0.00392157, 0.05490196],\n",
            "       [0.8509804 , 0.8980392 , 0.94509804, 0.76862746, 0.8862745 ],\n",
            "       [0.5921569 , 0.8627451 , 0.8156863 , 0.78431374, 1.        ],\n",
            "       [0.7764706 , 0.8235294 , 0.9019608 , 0.99607843, 0.72156864],\n",
            "       [0.7019608 , 0.8509804 , 0.79607844, 0.8156863 , 0.60784316],\n",
            "       [0.32941177, 0.54509807, 0.4509804 , 0.39215687, 0.44313726],\n",
            "       [0.40392157, 0.63529414, 0.49411765, 0.57254905, 0.5529412 ],\n",
            "       [0.40392157, 0.41568628, 0.5803922 , 0.5294118 , 0.3882353 ],\n",
            "       [0.03529412, 0.16078432, 0.03529412, 0.10588235, 0.10980392],\n",
            "       [0.44313726, 0.47843137, 0.46666667, 0.41568628, 0.49803922],\n",
            "       [0.40392157, 0.49019608, 0.5764706 , 0.54509807, 0.44313726],\n",
            "       [0.40392157, 0.4       , 0.5411765 , 0.50980395, 0.33333334],\n",
            "       [0.40392157, 0.4       , 0.5254902 , 0.60784316, 0.3882353 ],\n",
            "       [0.25882354, 0.13333334, 0.21568628, 0.26666668, 0.        ],\n",
            "       [0.44313726, 0.4627451 , 0.5058824 , 0.47058824, 0.21960784],\n",
            "       [0.32941177, 0.40784314, 0.5254902 , 0.43137255, 0.3882353 ],\n",
            "       [0.21960784, 0.21568628, 0.2901961 , 0.02352941, 0.16470589],\n",
            "       [0.40392157, 0.49019608, 0.43137255, 0.50980395, 0.27450982],\n",
            "       [0.03529412, 0.2509804 , 0.1254902 , 0.        , 0.10980392],\n",
            "       [0.03529412, 0.2509804 , 0.27058825, 0.19215687, 0.10980392]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(45,), dtype=int32, numpy=\n",
            "array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2,\n",
            "       2, 2, 2, 0, 2, 2, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
            "       0], dtype=int32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Model**"
      ],
      "metadata": {
        "id": "dSBlaBAaAYEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def create_mlp(input_size, hidden_size1, hidden_size2, output_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.InputLayer(shape=(input_size,)),\n",
        "        layers.Dense(hidden_size1, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        layers.Dense(hidden_size2, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        layers.Dense(output_size, kernel_regularizer=l2(0.001))\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = create_mlp(INPUT_SIZE, HIDDEN_SIZE_1, HIDDEN_SIZE_2, OUTPUT_SIZE)\n",
        "opt = Adam(learning_rate=LEARNING_RATE, )\n",
        "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "RTuXXZnTKVJ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f3e91929-0af2-40bf-b32c-ca37a419a710",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m363\u001b[0m (1.42 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">363</span> (1.42 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m363\u001b[0m (1.42 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">363</span> (1.42 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train from Scratch in FP32**"
      ],
      "metadata": {
        "id": "OSfrYoT5_vc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial non-quant training\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_dataset\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "trLEGuB-ItPp",
        "outputId": "3d12b89e-4826-4664-c628-f5f2533ab624"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step - accuracy: 0.3667 - loss: 1.0952 - val_accuracy: 0.3333 - val_loss: 1.0788\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3667 - loss: 1.0767 - val_accuracy: 0.3333 - val_loss: 1.0578\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.3600 - loss: 1.0578 - val_accuracy: 0.3333 - val_loss: 1.0376\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.3533 - loss: 1.0391 - val_accuracy: 0.3333 - val_loss: 1.0210\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3400 - loss: 1.0217 - val_accuracy: 0.3333 - val_loss: 1.0072\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.3333 - loss: 1.0070 - val_accuracy: 0.3333 - val_loss: 0.9942\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3400 - loss: 0.9939 - val_accuracy: 0.3333 - val_loss: 0.9813\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.3467 - loss: 0.9808 - val_accuracy: 0.3333 - val_loss: 0.9680\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3667 - loss: 0.9672 - val_accuracy: 0.3333 - val_loss: 0.9547\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3800 - loss: 0.9533 - val_accuracy: 0.3333 - val_loss: 0.9413\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.4267 - loss: 0.9389 - val_accuracy: 0.4444 - val_loss: 0.9277\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4800 - loss: 0.9243 - val_accuracy: 0.4444 - val_loss: 0.9143\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.4867 - loss: 0.9093 - val_accuracy: 0.4889 - val_loss: 0.9004\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.5333 - loss: 0.8943 - val_accuracy: 0.5111 - val_loss: 0.8856\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5400 - loss: 0.8791 - val_accuracy: 0.5333 - val_loss: 0.8707\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5467 - loss: 0.8638 - val_accuracy: 0.5556 - val_loss: 0.8558\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5533 - loss: 0.8483 - val_accuracy: 0.5778 - val_loss: 0.8408\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5800 - loss: 0.8327 - val_accuracy: 0.5778 - val_loss: 0.8264\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5867 - loss: 0.8174 - val_accuracy: 0.5778 - val_loss: 0.8118\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6133 - loss: 0.8023 - val_accuracy: 0.6000 - val_loss: 0.7975\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6333 - loss: 0.7874 - val_accuracy: 0.6000 - val_loss: 0.7833\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6333 - loss: 0.7726 - val_accuracy: 0.6222 - val_loss: 0.7691\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.6400 - loss: 0.7578 - val_accuracy: 0.6222 - val_loss: 0.7548\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6400 - loss: 0.7431 - val_accuracy: 0.6444 - val_loss: 0.7406\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.6467 - loss: 0.7284 - val_accuracy: 0.6444 - val_loss: 0.7264\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6467 - loss: 0.7138 - val_accuracy: 0.6444 - val_loss: 0.7123\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6533 - loss: 0.6992 - val_accuracy: 0.6667 - val_loss: 0.6979\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.6667 - loss: 0.6846 - val_accuracy: 0.6667 - val_loss: 0.6833\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6733 - loss: 0.6699 - val_accuracy: 0.6667 - val_loss: 0.6686\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7000 - loss: 0.6553 - val_accuracy: 0.6889 - val_loss: 0.6538\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7000 - loss: 0.6405 - val_accuracy: 0.7111 - val_loss: 0.6389\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7400 - loss: 0.6258 - val_accuracy: 0.7778 - val_loss: 0.6240\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7733 - loss: 0.6111 - val_accuracy: 0.7778 - val_loss: 0.6090\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8067 - loss: 0.5963 - val_accuracy: 0.8667 - val_loss: 0.5940\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.8467 - loss: 0.5814 - val_accuracy: 0.8889 - val_loss: 0.5789\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8733 - loss: 0.5665 - val_accuracy: 0.8889 - val_loss: 0.5640\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8800 - loss: 0.5517 - val_accuracy: 0.8889 - val_loss: 0.5491\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.8933 - loss: 0.5369 - val_accuracy: 0.9111 - val_loss: 0.5344\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.9400 - loss: 0.5223 - val_accuracy: 0.9333 - val_loss: 0.5198\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9533 - loss: 0.5077 - val_accuracy: 0.9333 - val_loss: 0.5053\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.9600 - loss: 0.4932 - val_accuracy: 0.9556 - val_loss: 0.4910\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9933 - loss: 0.4789 - val_accuracy: 0.9556 - val_loss: 0.4768\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9933 - loss: 0.4647 - val_accuracy: 0.9778 - val_loss: 0.4624\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9933 - loss: 0.4505 - val_accuracy: 0.9778 - val_loss: 0.4479\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.4365 - val_accuracy: 1.0000 - val_loss: 0.4335\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.4225 - val_accuracy: 1.0000 - val_loss: 0.4192\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.4086 - val_accuracy: 1.0000 - val_loss: 0.4050\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.3948 - val_accuracy: 1.0000 - val_loss: 0.3910\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.3812 - val_accuracy: 1.0000 - val_loss: 0.3771\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.3677 - val_accuracy: 1.0000 - val_loss: 0.3635\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.3545 - val_accuracy: 1.0000 - val_loss: 0.3500\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.3415 - val_accuracy: 1.0000 - val_loss: 0.3368\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.3288 - val_accuracy: 1.0000 - val_loss: 0.3239\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.3164 - val_accuracy: 1.0000 - val_loss: 0.3113\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.3042 - val_accuracy: 1.0000 - val_loss: 0.2991\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.2924 - val_accuracy: 1.0000 - val_loss: 0.2871\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.2808 - val_accuracy: 1.0000 - val_loss: 0.2755\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.2696 - val_accuracy: 1.0000 - val_loss: 0.2642\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.2586 - val_accuracy: 1.0000 - val_loss: 0.2533\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 0.2479 - val_accuracy: 1.0000 - val_loss: 0.2426\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.2376 - val_accuracy: 1.0000 - val_loss: 0.2323\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.2275 - val_accuracy: 1.0000 - val_loss: 0.2224\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.2179 - val_accuracy: 1.0000 - val_loss: 0.2129\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2086 - val_accuracy: 1.0000 - val_loss: 0.2037\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1997 - val_accuracy: 1.0000 - val_loss: 0.1950\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.1912 - val_accuracy: 1.0000 - val_loss: 0.1866\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.1830 - val_accuracy: 1.0000 - val_loss: 0.1787\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1751 - val_accuracy: 1.0000 - val_loss: 0.1711\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.1677 - val_accuracy: 1.0000 - val_loss: 0.1639\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.1605 - val_accuracy: 1.0000 - val_loss: 0.1571\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.1537 - val_accuracy: 1.0000 - val_loss: 0.1507\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1473 - val_accuracy: 1.0000 - val_loss: 0.1445\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.1413 - val_accuracy: 1.0000 - val_loss: 0.1387\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.1355 - val_accuracy: 1.0000 - val_loss: 0.1333\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1302 - val_accuracy: 1.0000 - val_loss: 0.1282\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1251 - val_accuracy: 1.0000 - val_loss: 0.1235\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1203 - val_accuracy: 1.0000 - val_loss: 0.1191\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1159 - val_accuracy: 1.0000 - val_loss: 0.1150\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1118 - val_accuracy: 1.0000 - val_loss: 0.1111\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1079 - val_accuracy: 1.0000 - val_loss: 0.1074\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.1043 - val_accuracy: 1.0000 - val_loss: 0.1039\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.1009 - val_accuracy: 1.0000 - val_loss: 0.1007\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0977 - val_accuracy: 1.0000 - val_loss: 0.0977\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0948 - val_accuracy: 1.0000 - val_loss: 0.0949\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0920 - val_accuracy: 1.0000 - val_loss: 0.0923\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0895 - val_accuracy: 1.0000 - val_loss: 0.0899\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0871 - val_accuracy: 1.0000 - val_loss: 0.0877\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0850 - val_accuracy: 1.0000 - val_loss: 0.0856\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0829 - val_accuracy: 1.0000 - val_loss: 0.0836\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0810 - val_accuracy: 1.0000 - val_loss: 0.0818\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0793 - val_accuracy: 1.0000 - val_loss: 0.0801\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0777 - val_accuracy: 1.0000 - val_loss: 0.0786\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0761 - val_accuracy: 1.0000 - val_loss: 0.0771\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0747 - val_accuracy: 1.0000 - val_loss: 0.0758\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0734 - val_accuracy: 1.0000 - val_loss: 0.0745\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0722 - val_accuracy: 1.0000 - val_loss: 0.0734\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0711 - val_accuracy: 1.0000 - val_loss: 0.0723\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0700 - val_accuracy: 1.0000 - val_loss: 0.0712\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0691 - val_accuracy: 1.0000 - val_loss: 0.0703\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0682 - val_accuracy: 1.0000 - val_loss: 0.0694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vizualize Training History**"
      ],
      "metadata": {
        "id": "17dCr9zgAnQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "BpMKkmkDmweF",
        "outputId": "bf71e39a-9653-4391-c429-a91091521ed2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Set Classification Accuracy of FP32 Model**"
      ],
      "metadata": {
        "id": "egHE_K6vArh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the FP32 model\n",
        "results = model.evaluate(test_dataset)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IElgrf-TJJPC",
        "outputId": "c7cd3597-5c5f-4874-9817-89128ef38257"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0694\n",
            "Test Loss: 0.06937658786773682, Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convert to TFLite Model**"
      ],
      "metadata": {
        "id": "tdyvZiHWA-A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "# Print tensor details\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "for tensor in interpreter.get_tensor_details():\n",
        "    print(tensor['name'], tensor['dtype'])\n",
        "    try:\n",
        "        # Attempt to get tensor data\n",
        "        tensor_data = interpreter.get_tensor(tensor['index'])\n",
        "        print(tensor_data)\n",
        "    except ValueError:\n",
        "        # Skip tensors with null data\n",
        "        print(f\"Skipping tensor '{tensor['name']}' as it has null data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC6reRpb_00G",
        "outputId": "65450796-6f92-453e-ccc8-0175a0eeed52"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpjqv3z2wu'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 5), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138937665602768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138937665604496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138934993286736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138934993286544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138937665602576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138934993288464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "serving_default_keras_tensor:0 <class 'numpy.float32'>\n",
            "[[6.8544985e-08 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
            "arith.constant <class 'numpy.float32'>\n",
            "[[ 7.8178287e-01 -7.7036583e-01 -1.8107031e-01 -8.2380658e-01\n",
            "  -1.0451335e-03 -1.4726311e-01  7.6500070e-04  9.9181920e-01\n",
            "  -9.5295942e-01  5.0272363e-01]\n",
            " [-5.1241484e-02 -3.2945046e-01 -8.6744368e-04 -4.3156418e-01\n",
            "   2.5571215e-01 -3.8719758e-01  2.9063283e-04 -1.0024581e+00\n",
            "   8.6909461e-01  1.0849832e+00]\n",
            " [-5.4308343e-01  9.6285307e-01 -1.6971251e-01  5.5308729e-01\n",
            "   6.5531145e-04  3.8071921e-01 -8.0285754e-05 -6.2166566e-01\n",
            "   7.0857388e-01 -9.3644255e-01]]\n",
            "arith.constant1 <class 'numpy.float32'>\n",
            "[[ 6.37760878e-01  2.32438534e-01 -1.87058235e-03 -2.68326253e-01\n",
            "  -2.62383550e-01  5.44419408e-01  8.10675174e-02  6.13413565e-02\n",
            "  -1.25183657e-01 -1.84025690e-01  9.16254648e-04 -3.46655458e-01\n",
            "   5.36525846e-01  5.84597117e-04  1.67623937e-01 -4.51806554e-04\n",
            "   7.62399659e-02  4.37255740e-01  4.47459787e-01  1.93127501e-03]\n",
            " [-4.12793338e-01  1.67376101e-01  6.06856979e-02  4.29440975e-01\n",
            "   7.72682965e-01 -2.82227516e-01  5.77512383e-02 -9.39120582e-05\n",
            "   3.30904931e-01  5.77383459e-01 -5.49123361e-05  8.44730288e-02\n",
            "  -7.74520755e-01  5.38163113e-06  6.27296090e-01 -5.78707978e-02\n",
            "  -7.64173269e-02 -4.23627913e-01 -6.80069566e-01 -2.24767393e-03]\n",
            " [-2.32223142e-03  1.92196458e-03 -2.77853513e-04  4.35806140e-02\n",
            "   2.29171666e-04  7.03831166e-02 -1.33530321e-02 -2.34002136e-02\n",
            "   3.08213010e-02 -2.48553231e-02 -4.45346726e-04 -1.06003294e-02\n",
            "  -3.24319495e-04 -8.60677508e-04  5.57648455e-05 -1.34336937e-04\n",
            "  -7.50846404e-04  9.43251420e-03 -1.96757028e-03 -1.07446956e-02]\n",
            " [-3.33697975e-01  2.66072243e-01  7.98443928e-02  6.60630882e-01\n",
            "   6.65813863e-01 -4.04971182e-01  2.16718227e-01 -5.43216884e-05\n",
            "   7.02730656e-01  6.03429854e-01  7.10751337e-04  6.68056726e-01\n",
            "  -6.50870144e-01 -2.39823875e-03  1.88344374e-01  7.52844885e-02\n",
            "   1.82792366e-01 -8.55490148e-01 -3.53100538e-01  4.43372497e-04]\n",
            " [ 6.31390605e-03 -3.65954638e-02  4.17923933e-04 -8.83282162e-03\n",
            "   2.19102993e-04  3.45733352e-02  4.76435089e-04 -1.52359006e-03\n",
            "   3.24412584e-02  3.22653702e-03  7.14947805e-02 -1.22604452e-01\n",
            "   1.22175060e-01 -1.55185808e-05  1.74845918e-04  9.12473537e-03\n",
            "   8.21598843e-02 -1.79461613e-02 -1.52984513e-02  6.13407698e-04]\n",
            " [-2.70721257e-01 -2.16486424e-01  2.12207790e-02  1.54396087e-01\n",
            "   3.16809356e-01 -2.51011103e-01  3.01504582e-01  4.97292876e-02\n",
            "   3.23253959e-01  8.90648291e-02  1.93055021e-05  3.33338290e-01\n",
            "  -3.08185220e-01 -1.25830484e-04  1.57981589e-01 -4.07701870e-03\n",
            "  -3.30139697e-02 -3.05660963e-01 -2.66428620e-01  1.70854814e-02]\n",
            " [ 1.09769244e-04 -2.13251170e-03 -9.61867772e-05 -2.58689597e-02\n",
            "  -5.85788041e-02 -5.23090421e-05  2.29313213e-04  3.27581391e-02\n",
            "   2.27377983e-03  9.15964076e-04 -5.31789251e-02  2.37030000e-03\n",
            "  -1.35809423e-05  4.55433008e-04  6.29734248e-04  1.97696351e-02\n",
            "   2.31010769e-03  2.04380354e-04 -1.00612662e-04 -2.02167360e-03]\n",
            " [ 5.26460469e-01  2.53603280e-01 -3.93138006e-02 -6.41947687e-01\n",
            "  -6.67731285e-01  8.95463526e-01 -4.62095410e-01 -1.07594142e-02\n",
            "  -1.20019384e-01 -4.68616456e-01  1.05258287e-03 -7.97607303e-02\n",
            "   5.81711650e-01 -1.01662427e-02 -6.69456661e-01 -1.40261080e-03\n",
            "   3.01953614e-01  8.74279678e-01  8.12966704e-01 -3.93205235e-04]\n",
            " [-2.47210830e-01 -1.18765108e-01  5.66061062e-04  1.96284484e-02\n",
            "   1.80528879e-01 -1.65320620e-01  5.91533363e-01 -1.52580513e-04\n",
            "   2.93057233e-01  4.86253947e-01 -3.26204259e-04  3.16104114e-01\n",
            "  -4.28068072e-01 -1.26420949e-02  5.29582024e-01  6.29093796e-02\n",
            "   6.78579092e-01 -1.45443484e-01 -3.71354282e-01 -5.18999100e-02]\n",
            " [ 3.80562693e-01  3.85735631e-01 -7.06319552e-05 -5.55099308e-01\n",
            "  -2.64340967e-01  3.55587125e-01 -5.56137681e-01 -6.56978860e-02\n",
            "  -7.55371451e-01  5.16990185e-01 -3.57259102e-02 -4.65135336e-01\n",
            "   3.98499817e-01  5.97842562e-04  6.36824131e-01 -6.44253276e-04\n",
            "   7.71183908e-01  2.91250825e-01  7.12846875e-01  9.86290909e-03]]\n",
            "arith.constant2 <class 'numpy.float32'>\n",
            "[ 0.3370495   0.36406872 -0.36952686]\n",
            "sequential_1/dense_1_2/BiasAdd/ReadVariableOp <class 'numpy.float32'>\n",
            "[ 0.39243102 -0.3671576  -0.06928889 -0.2894962  -0.14421082 -0.22795801\n",
            " -0.04968149  0.26807624 -0.04228058  0.4110326 ]\n",
            "sequential_1/dense_1/BiasAdd/ReadVariableOp <class 'numpy.float32'>\n",
            "[ 0.45162353  0.30273715 -0.08098539 -0.35948992 -0.35800692  0.47762787\n",
            " -0.29825863 -0.05606421 -0.4954758  -0.16913733 -0.05421569 -0.42297453\n",
            "  0.45867646  0.         -0.09157077 -0.09300718  0.46971646  0.46668488\n",
            "  0.4491897   0.        ]\n",
            "sequential_1/dense_1/MatMul <class 'numpy.float32'>\n",
            "[[ 2.0483028e-02 -2.6847100e-01 -1.6182904e-01  1.5753927e-02\n",
            "  -8.9359187e-02]\n",
            " [ 8.2202405e-02  2.3708422e-01 -3.9926503e-02  1.9298276e-01\n",
            "   3.4715492e-01]\n",
            " [-4.6434764e-02  2.1968192e-01 -2.6860563e-02 -1.0056459e-01\n",
            "  -7.6162443e-02]\n",
            " [ 7.7337861e-01  7.7137239e-02  9.5166273e-02  4.6021155e-01\n",
            "   1.2257555e-01]\n",
            " [-4.5428760e-02  6.9634539e-01  7.4454349e-01  1.7088486e-01\n",
            "   6.7644387e-02]\n",
            " [ 4.2796474e-02 -2.2550973e-01 -2.0748895e-01  7.7473402e-02\n",
            "  -2.2107865e-01]\n",
            " [ 7.8400803e-01  2.8303644e-01  2.7990171e-01  1.4067499e-01\n",
            "   6.3518184e-01]\n",
            " [-9.8944595e-03 -4.9955648e-04  2.0262667e-03 -3.4836761e-05\n",
            "   4.6929378e-02]\n",
            " [ 3.5003525e-01  3.1351888e-01 -2.4796070e-01  4.8976052e-01\n",
            "   3.7258241e-01]\n",
            " [ 3.9325929e-01 -8.2697449e-03  4.8889062e-01  6.0666072e-01\n",
            "   2.9083401e-01]\n",
            " [-4.9850274e-02 -5.1449786e-04  2.7218874e-04  1.8231811e-03\n",
            "  -1.6743508e-04]\n",
            " [ 2.7368334e-01  6.9796252e-01  1.1064957e-01  5.5090916e-01\n",
            "   4.4411168e-01]\n",
            " [ 7.4698254e-02 -3.7109199e-01 -2.1618512e-01  1.3314492e-01\n",
            "  -1.1640884e-01]\n",
            " [-1.3193303e-04  1.9242843e-04 -3.3106472e-02  1.6462486e-04\n",
            "  -2.7871016e-02]\n",
            " [ 2.7048141e-01  6.6250563e-02  5.8052063e-01  4.3933678e-01\n",
            "   6.4900869e-01]\n",
            " [ 5.6607679e-02 -5.4126512e-02  1.2138797e-01 -2.8265545e-02\n",
            "   5.4971653e-04]\n",
            " [-2.1836923e-01  5.0453222e-01  2.6761431e-01  7.4604046e-01\n",
            "   5.1656550e-01]\n",
            " [-3.1106666e-01 -2.5949407e-01 -1.8944268e-01  1.0488674e-01\n",
            "   1.2759206e-01]\n",
            " [-2.1282011e-01  8.2832590e-02 -2.0407657e-01 -5.3949477e-03\n",
            "  -1.9188197e-01]\n",
            " [-6.1900239e-02  9.2160626e-04 -7.9122789e-02 -7.3125586e-03\n",
            "  -6.5227956e-02]]\n",
            "sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/BiasAdd <class 'numpy.float32'>\n",
            "Skipping tensor 'sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/BiasAdd' as it has null data.\n",
            "sequential_1/dense_1_2/MatMul;sequential_1/dense_1_2/Relu;sequential_1/dense_1_2/BiasAdd <class 'numpy.float32'>\n",
            "Skipping tensor 'sequential_1/dense_1_2/MatMul;sequential_1/dense_1_2/Relu;sequential_1/dense_1_2/BiasAdd' as it has null data.\n",
            "StatefulPartitionedCall_1:0 <class 'numpy.float32'>\n",
            "[[7.1684781e-08 0.0000000e+00 1.6684753e-26]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convert to Quantized Model**"
      ],
      "metadata": {
        "id": "C1gaSy-8xaMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide a representative dataset to guide the quantization process\n",
        "def representative_dataset_gen():\n",
        "    for data, _ in test_dataset.unbatch().batch(1).take(100):\n",
        "        yield [data]\n",
        "\n",
        "# Convert the model to int8 format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "converter.experimental_new_quantizer = False  # Optional: Use the default quantizer\n",
        "converter._experimental_disable_per_channel = True\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "# Save the model\n",
        "with open('model_quantized.tflite', 'wb') as f:\n",
        "  f.write(tflite_quant_model)\n",
        "\n",
        "# Print tensor details\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "for tensor in interpreter.get_tensor_details():\n",
        "    print(tensor['name'], tensor['dtype'])\n",
        "    try:\n",
        "        # Attempt to get tensor data\n",
        "        tensor_data = interpreter.get_tensor(tensor['index'])\n",
        "        print(tensor_data)\n",
        "    except ValueError:\n",
        "        # Skip tensors with null data\n",
        "        print(f\"Skipping tensor '{tensor['name']}' as it has null data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu50RF1HBJZ_",
        "outputId": "ebc7abec-4482-4370-8831-849957e215e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpmodejj64'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 5), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138937665602768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138937665604496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138934993286736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138934993286544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138937665602576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138934993288464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "serving_default_keras_tensor:0_int8 <class 'numpy.int8'>\n",
            "[[0 0 0 0 0]]\n",
            "arith.constant <class 'numpy.int8'>\n",
            "[[  92  -90  -21  -96    0  -17    0  116 -112   59]\n",
            " [  -6  -39    0  -51   30  -45    0 -117  102  127]\n",
            " [ -64  113  -20   65    0   45    0  -73   83 -110]]\n",
            "arith.constant1 <class 'numpy.int8'>\n",
            "[[  90   33    0  -38  -37   77   11    9  -18  -26    0  -49   76    0\n",
            "    24    0   11   62   63    0]\n",
            " [ -59   24    9   61  110  -40    8    0   47   82    0   12 -110    0\n",
            "    89   -8  -11  -60  -96    0]\n",
            " [   0    0    0    6    0   10   -2   -3    4   -4    0   -2    0    0\n",
            "     0    0    0    1    0   -2]\n",
            " [ -47   38   11   94   94  -57   31    0  100   86    0   95  -92    0\n",
            "    27   11   26 -121  -50    0]\n",
            " [   1   -5    0   -1    0    5    0    0    5    0   10  -17   17    0\n",
            "     0    1   12   -3   -2    0]\n",
            " [ -38  -31    3   22   45  -36   43    7   46   13    0   47  -44    0\n",
            "    22   -1   -5  -43  -38    2]\n",
            " [   0    0    0   -4   -8    0    0    5    0    0   -8    0    0    0\n",
            "     0    3    0    0    0    0]\n",
            " [  75   36   -6  -91  -95  127  -66   -2  -17  -66    0  -11   83   -1\n",
            "   -95    0   43  124  115    0]\n",
            " [ -35  -17    0    3   26  -23   84    0   42   69    0   45  -61   -2\n",
            "    75    9   96  -21  -53   -7]\n",
            " [  54   55    0  -79  -37   50  -79   -9 -107   73   -5  -66   57    0\n",
            "    90    0  109   41  101    1]]\n",
            "arith.constant2 <class 'numpy.int32'>\n",
            "[ 1992  2151 -2183]\n",
            "sequential_1/dense_1_2/BiasAdd/ReadVariableOp <class 'numpy.int32'>\n",
            "[ 5975 -5591 -1055 -4408 -2196 -3471  -756  4082  -644  6259]\n",
            "sequential_1/dense_1/BiasAdd/ReadVariableOp <class 'numpy.int32'>\n",
            "[ 18655  12505  -3345 -14849 -14788  19729 -12320  -2316 -20467  -6987\n",
            "  -2239 -17472  18947      0  -3783  -3842  19403  19277  18555      0]\n",
            "sequential_1/dense_1/MatMul <class 'numpy.int8'>\n",
            "[[  3 -43 -26   3 -14]\n",
            " [ 13  38  -6  31  56]\n",
            " [ -8  36  -4 -16 -12]\n",
            " [125  12  15  75  20]\n",
            " [ -7 113 121  28  11]\n",
            " [  7 -37 -34  13 -36]\n",
            " [127  46  45  23 103]\n",
            " [ -2   0   0   0   8]\n",
            " [ 57  51 -40  79  60]\n",
            " [ 64  -1  79  98  47]\n",
            " [ -8   0   0   0   0]\n",
            " [ 44 113  18  89  72]\n",
            " [ 12 -60 -35  22 -19]\n",
            " [  0   0  -5   0  -5]\n",
            " [ 44  11  94  71 105]\n",
            " [  9  -9  20  -5   0]\n",
            " [-35  82  43 121  84]\n",
            " [-50 -42 -31  17  21]\n",
            " [-34  13 -33  -1 -31]\n",
            " [-10   0 -13  -1 -11]]\n",
            "sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/BiasAdd <class 'numpy.int8'>\n",
            "Skipping tensor 'sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/BiasAdd' as it has null data.\n",
            "sequential_1/dense_1_2/MatMul;sequential_1/dense_1_2/Relu;sequential_1/dense_1_2/BiasAdd <class 'numpy.int8'>\n",
            "Skipping tensor 'sequential_1/dense_1_2/MatMul;sequential_1/dense_1_2/Relu;sequential_1/dense_1_2/BiasAdd' as it has null data.\n",
            "StatefulPartitionedCall_1:0_int8 <class 'numpy.int8'>\n",
            "[[-128    0    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Set Classification Accuracy of 8-bit Model**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SZZ-Oth4nJOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test accuracy of quantized model\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "correct = 0.0\n",
        "total = 0.0\n",
        "\n",
        "# Define the transformation function\n",
        "def convert_to_int8(X, y):\n",
        "    X = tf.cast((X*255)-128, tf.int8)  # Multiply by 255 and subtract 128 cast to int8\n",
        "    return X, y\n",
        "\n",
        "# Apply the transformation to the dataset\n",
        "test_dataset_quantized_inputs = test_dataset.map(convert_to_int8).unbatch()\n",
        "\n",
        "# Example: Inspect the first batch\n",
        "for X_batch, y_batch in test_dataset_quantized_inputs.take(1):\n",
        "    print(X_batch.numpy(), y_batch.numpy())\n",
        "for input, label in test_dataset_quantized_inputs.batch(1):\n",
        "    interpreter.set_tensor(input_details[0]['index'], input.numpy().astype('int8'))\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    total += 1\n",
        "    if output.argmax() == label.numpy()[0]:\n",
        "        correct += 1\n",
        "\n",
        "print(f\"Quantized Model Test Set Accuracy: {correct / total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSPokUuAfoOQ",
        "outputId": "b31ebef6-34e0-4eed-ed8a-92ee98a6248a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ -6 -24  -6   1  -1] 1\n",
            "Quantized Model Test Set Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the quantized TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Extract tensor details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "all_tensor_details = interpreter.get_tensor_details()\n",
        "\n",
        "# Extract weights, biases, scales, and zero points from allocated tensors\n",
        "quantized_params = {}\n",
        "for tensor in all_tensor_details:\n",
        "    # Check if the tensor has quantization parameters and valid data\n",
        "    try:\n",
        "        # Attempt to get tensor data\n",
        "        tensor_data = interpreter.get_tensor(tensor['index'])\n",
        "\n",
        "        if 'quantization_parameters' in tensor and tensor['quantization_parameters']['scales'].size > 0:\n",
        "            quantized_params[tensor['name']] = {\n",
        "                'values': tensor_data,\n",
        "                'scale': tensor['quantization_parameters']['scales'],\n",
        "                'zero_point': tensor['quantization_parameters']['zero_points']\n",
        "            }\n",
        "    except ValueError:\n",
        "        # Skip tensors with null data\n",
        "        if 'quantization_parameters' in tensor and tensor['quantization_parameters']['scales'].size > 0:\n",
        "            quantized_params[tensor['name']] = {\n",
        "                'scale': tensor['quantization_parameters']['scales'],\n",
        "                'zero_point': tensor['quantization_parameters']['zero_points']\n",
        "            }\n",
        "        print(f\"Skipping tensor '{tensor['name']}' as it has null data.\")\n",
        "\n",
        "print(\"Quantized parameters extracted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv4RuhPA3MDI",
        "outputId": "a1d631dc-3bf2-432b-c226-83391df52fb6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping tensor 'sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/BiasAdd' as it has null data.\n",
            "Skipping tensor 'sequential_1/dense_1_2/MatMul;sequential_1/dense_1_2/Relu;sequential_1/dense_1_2/BiasAdd' as it has null data.\n",
            "Quantized parameters extracted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Print Names, Weights, Scales, and Zero Points of Quantized Model Tensors'**"
      ],
      "metadata": {
        "id": "V3QtTCSOe_8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, params in quantized_params.items():\n",
        "    print(f\"{name} - Scale: {params['scale']}, Zero Point: {params['zero_point']}\")\n",
        "    if 'values' in params:\n",
        "      print(params['values'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vO6T2gMerb9",
        "outputId": "0bd22e57-0430-47eb-e1f7-62e75c1c89da"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "serving_default_keras_tensor:0_int8 - Scale: [0.00392157], Zero Point: [-128]\n",
            "[[0 0 0 0 0]]\n",
            "arith.constant - Scale: [0.00854317], Zero Point: [0]\n",
            "[[  92  -90  -21  -96    0  -17    0  116 -112   59]\n",
            " [  -6  -39    0  -51   30  -45    0 -117  102  127]\n",
            " [ -64  113  -20   65    0   45    0  -73   83 -110]]\n",
            "arith.constant1 - Scale: [0.00705089], Zero Point: [0]\n",
            "[[  90   33    0  -38  -37   77   11    9  -18  -26    0  -49   76    0\n",
            "    24    0   11   62   63    0]\n",
            " [ -59   24    9   61  110  -40    8    0   47   82    0   12 -110    0\n",
            "    89   -8  -11  -60  -96    0]\n",
            " [   0    0    0    6    0   10   -2   -3    4   -4    0   -2    0    0\n",
            "     0    0    0    1    0   -2]\n",
            " [ -47   38   11   94   94  -57   31    0  100   86    0   95  -92    0\n",
            "    27   11   26 -121  -50    0]\n",
            " [   1   -5    0   -1    0    5    0    0    5    0   10  -17   17    0\n",
            "     0    1   12   -3   -2    0]\n",
            " [ -38  -31    3   22   45  -36   43    7   46   13    0   47  -44    0\n",
            "    22   -1   -5  -43  -38    2]\n",
            " [   0    0    0   -4   -8    0    0    5    0    0   -8    0    0    0\n",
            "     0    3    0    0    0    0]\n",
            " [  75   36   -6  -91  -95  127  -66   -2  -17  -66    0  -11   83   -1\n",
            "   -95    0   43  124  115    0]\n",
            " [ -35  -17    0    3   26  -23   84    0   42   69    0   45  -61   -2\n",
            "    75    9   96  -21  -53   -7]\n",
            " [  54   55    0  -79  -37   50  -79   -9 -107   73   -5  -66   57    0\n",
            "    90    0  109   41  101    1]]\n",
            "arith.constant2 - Scale: [0.00016924], Zero Point: [0]\n",
            "[ 1992  2151 -2183]\n",
            "sequential_1/dense_1_2/BiasAdd/ReadVariableOp - Scale: [6.567452e-05], Zero Point: [0]\n",
            "[ 5975 -5591 -1055 -4408 -2196 -3471  -756  4082  -644  6259]\n",
            "sequential_1/dense_1/BiasAdd/ReadVariableOp - Scale: [2.4208988e-05], Zero Point: [0]\n",
            "[ 18655  12505  -3345 -14849 -14788  19729 -12320  -2316 -20467  -6987\n",
            "  -2239 -17472  18947      0  -3783  -3842  19403  19277  18555      0]\n",
            "sequential_1/dense_1/MatMul - Scale: [0.00617329], Zero Point: [0]\n",
            "[[  3 -43 -26   3 -14]\n",
            " [ 13  38  -6  31  56]\n",
            " [ -8  36  -4 -16 -12]\n",
            " [125  12  15  75  20]\n",
            " [ -7 113 121  28  11]\n",
            " [  7 -37 -34  13 -36]\n",
            " [127  46  45  23 103]\n",
            " [ -2   0   0   0   8]\n",
            " [ 57  51 -40  79  60]\n",
            " [ 64  -1  79  98  47]\n",
            " [ -8   0   0   0   0]\n",
            " [ 44 113  18  89  72]\n",
            " [ 12 -60 -35  22 -19]\n",
            " [  0   0  -5   0  -5]\n",
            " [ 44  11  94  71 105]\n",
            " [  9  -9  20  -5   0]\n",
            " [-35  82  43 121  84]\n",
            " [-50 -42 -31  17  21]\n",
            " [-34  13 -33  -1 -31]\n",
            " [-10   0 -13  -1 -11]]\n",
            "sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/BiasAdd - Scale: [0.00931435], Zero Point: [-128]\n",
            "sequential_1/dense_1_2/MatMul;sequential_1/dense_1_2/Relu;sequential_1/dense_1_2/BiasAdd - Scale: [0.01980952], Zero Point: [-128]\n",
            "StatefulPartitionedCall_1:0_int8 - Scale: [0.07640018], Zero Point: [13]\n",
            "[[118  97 -22]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Map TFLite Provided Names to Intuitive Ones**\n",
        "The TFLite Layer names after quantization are not very intuitive.\n",
        "Use the names above + the [Netron](https://netron.app/) application to update dictionary below so that it is very clear which layer is which. *You may need to update the names if any changes are made to the notebook.*"
      ],
      "metadata": {
        "id": "dDUXkdPJAlNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, params in quantized_params.items():\n",
        "    print(f\"{name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5CLjrd6r2M_",
        "outputId": "20d22f0d-f0ad-4bb3-9267-5935a435d787"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "serving_default_keras_tensor:0_int8\n",
            "arith.constant\n",
            "arith.constant1\n",
            "arith.constant2\n",
            "sequential_1/dense_1_2/BiasAdd/ReadVariableOp\n",
            "sequential_1/dense_1/BiasAdd/ReadVariableOp\n",
            "sequential_1/dense_1/MatMul\n",
            "sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/BiasAdd\n",
            "sequential_1/dense_1_2/MatMul;sequential_1/dense_1_2/Relu;sequential_1/dense_1_2/BiasAdd\n",
            "StatefulPartitionedCall_1:0_int8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UQwlPsSStV4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, params in quantized_params.items():\n",
        "    print(f\"Tensor Name: {name}, shape: {params['values'].shape if 'values' in params else 'N/A'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxp3BjWMuiz6",
        "outputId": "e5ba571c-4909-4db1-d8b4-d44f1512e5ac"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor Name: serving_default_keras_tensor:0_int8, shape: (1, 5)\n",
            "Tensor Name: arith.constant, shape: (3, 10)\n",
            "Tensor Name: arith.constant1, shape: (10, 20)\n",
            "Tensor Name: arith.constant2, shape: (3,)\n",
            "Tensor Name: sequential_1/dense_1_2/BiasAdd/ReadVariableOp, shape: (10,)\n",
            "Tensor Name: sequential_1/dense_1/BiasAdd/ReadVariableOp, shape: (20,)\n",
            "Tensor Name: sequential_1/dense_1/MatMul, shape: (20, 5)\n",
            "Tensor Name: sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/BiasAdd, shape: N/A\n",
            "Tensor Name: sequential_1/dense_1_2/MatMul;sequential_1/dense_1_2/Relu;sequential_1/dense_1_2/BiasAdd, shape: N/A\n",
            "Tensor Name: StatefulPartitionedCall_1:0_int8, shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l4RXXe-rtuMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer name map\n",
        "layer_name_map = {\n",
        "    \"input_layer\": \"serving_default_keras_tensor:0_int8\",\n",
        "    \"layer_one_weights\": \"sequential_1/dense_1/MatMul\",\n",
        "    \"layer_one_bias\": \"sequential_1/dense_1/BiasAdd/ReadVariableOp\",\n",
        "    \"layer_one_output_activations\": \"sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/BiasAdd\",\n",
        "    \"layer_two_weights\": \"arith.constant1\",\n",
        "    \"layer_two_bias\": \"sequential_1/dense_1_2/BiasAdd/ReadVariableOp\",\n",
        "    \"layer_two_output_activations\": \"sequential_1/dense_1_2/MatMul;sequential_1/dense_1_2/Relu;sequential_1/dense_1_2/BiasAdd\",\n",
        "    \"layer_three_weights\": \"arith.constant\",\n",
        "    \"layer_three_bias\": \"arith.constant2\",\n",
        "    \"output_layer\": \"StatefulPartitionedCall_1:0_int8\"\n",
        "}"
      ],
      "metadata": {
        "id": "GqeYV9Ko_kAq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer_scale = quantized_params[layer_name_map[\"input_layer\"]][\"scale\"]\n",
        "input_layer_zero_point = quantized_params[layer_name_map[\"input_layer\"]][\"zero_point\"]\n",
        "\n",
        "layer_one_weights = quantized_params[layer_name_map[\"layer_one_weights\"]][\"values\"]\n",
        "layer_one_weights_scale = quantized_params[layer_name_map[\"layer_one_weights\"]][\"scale\"]\n",
        "layer_one_weights_zero_point = quantized_params[layer_name_map[\"layer_one_weights\"]][\"zero_point\"]\n",
        "layer_one_bias = quantized_params[layer_name_map[\"layer_one_bias\"]][\"values\"]\n",
        "\n",
        "layer_one_output_activations_scale = quantized_params[layer_name_map[\"layer_one_output_activations\"]][\"scale\"]\n",
        "layer_one_output_activations_zero_point = quantized_params[layer_name_map[\"layer_one_output_activations\"]][\"zero_point\"]\n",
        "\n",
        "layer_two_weights = quantized_params[layer_name_map[\"layer_two_weights\"]][\"values\"]\n",
        "layer_two_weights_scale = quantized_params[layer_name_map[\"layer_two_weights\"]][\"scale\"]\n",
        "layer_two_weights_zero_point = quantized_params[layer_name_map[\"layer_two_weights\"]][\"zero_point\"]\n",
        "layer_two_bias = quantized_params[layer_name_map[\"layer_two_bias\"]][\"values\"]\n",
        "\n",
        "layer_two_output_activations_scale = quantized_params[layer_name_map[\"layer_two_output_activations\"]][\"scale\"]\n",
        "layer_two_output_activations_zero_point = quantized_params[layer_name_map[\"layer_two_output_activations\"]][\"zero_point\"]\n",
        "\n",
        "layer_three_weights = quantized_params[layer_name_map[\"layer_three_weights\"]][\"values\"]\n",
        "layer_three_weights_scale = quantized_params[layer_name_map[\"layer_three_weights\"]][\"scale\"]\n",
        "layer_three_weights_zero_point = quantized_params[layer_name_map[\"layer_three_weights\"]][\"zero_point\"]\n",
        "layer_three_bias = quantized_params[layer_name_map[\"layer_three_bias\"]][\"values\"]\n",
        "\n",
        "output_layer_scale = quantized_params[layer_name_map[\"output_layer\"]][\"scale\"]\n",
        "output_layer_zero_point = quantized_params[layer_name_map[\"output_layer\"]][\"zero_point\"]"
      ],
      "metadata": {
        "id": "txvONXs98UfK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"input_layer_scale: {input_layer_scale}\")\n",
        "print(f\"input_layer_zero_point: {input_layer_zero_point}\")\n",
        "print(f\"layer_one_weights_scale: {layer_one_weights_scale}\")\n",
        "print(f\"layer_one_weights_zero_point: {layer_one_weights_zero_point}\")\n",
        "print(f\"layer_one_bias: {layer_one_bias}\")\n",
        "print(f\"layer_one_output_activations_scale: {layer_one_output_activations_scale}\")\n",
        "print(f\"layer_one_output_activations_zero_point: {layer_one_output_activations_zero_point}\")\n",
        "print(f\"layer_two_weights_scale: {layer_two_weights_scale}\")\n",
        "print(f\"layer_two_weights_zero_point: {layer_two_weights_zero_point}\")\n",
        "print(f\"layer_two_bias: {layer_two_bias}\")\n",
        "print(f\"layer_two_output_activations_scale: {layer_two_output_activations_scale}\")\n",
        "print(f\"layer_two_output_activations_zero_point: {layer_two_output_activations_zero_point}\")\n",
        "print(f\"layer_three_weights_scale: {layer_three_weights_scale}\")\n",
        "print(f\"layer_three_weights_zero_point: {layer_three_weights_zero_point}\")\n",
        "print(f\"layer_three_bias: {layer_three_bias}\")\n",
        "print(f\"output_layer_scale: {output_layer_scale}\")\n",
        "print(f\"output_layer_zero_point: {output_layer_zero_point}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jb_aBZxbTCI",
        "outputId": "d0f25866-6919-4029-eb72-f473d43aaae1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer_scale: [0.00392157]\n",
            "input_layer_zero_point: [-128]\n",
            "layer_one_weights_scale: [0.00617329]\n",
            "layer_one_weights_zero_point: [0]\n",
            "layer_one_bias: [ 18655  12505  -3345 -14849 -14788  19729 -12320  -2316 -20467  -6987\n",
            "  -2239 -17472  18947      0  -3783  -3842  19403  19277  18555      0]\n",
            "layer_one_output_activations_scale: [0.00931435]\n",
            "layer_one_output_activations_zero_point: [-128]\n",
            "layer_two_weights_scale: [0.00705089]\n",
            "layer_two_weights_zero_point: [0]\n",
            "layer_two_bias: [ 5975 -5591 -1055 -4408 -2196 -3471  -756  4082  -644  6259]\n",
            "layer_two_output_activations_scale: [0.01980952]\n",
            "layer_two_output_activations_zero_point: [-128]\n",
            "layer_three_weights_scale: [0.00854317]\n",
            "layer_three_weights_zero_point: [0]\n",
            "layer_three_bias: [ 1992  2151 -2183]\n",
            "output_layer_scale: [0.07640018]\n",
            "output_layer_zero_point: [13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Layer One Weights (comma-separated):\")\n",
        "for row in layer_one_weights:\n",
        "    print(','.join(map(str, row)))\n",
        "\n",
        "print(\"\\nLayer Two Weights (comma-separated):\")\n",
        "for row in layer_two_weights:\n",
        "    print(','.join(map(str, row)))\n",
        "\n",
        "print(\"\\nLayer Three Weights (comma-separated):\")\n",
        "for row in layer_three_weights:\n",
        "    print(','.join(map(str, row)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4iEk2Jjb_e2",
        "outputId": "1cf18d99-93c3-4121-d559-8425325b15e6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer One Weights (comma-separated):\n",
            "3,-43,-26,3,-14\n",
            "13,38,-6,31,56\n",
            "-8,36,-4,-16,-12\n",
            "125,12,15,75,20\n",
            "-7,113,121,28,11\n",
            "7,-37,-34,13,-36\n",
            "127,46,45,23,103\n",
            "-2,0,0,0,8\n",
            "57,51,-40,79,60\n",
            "64,-1,79,98,47\n",
            "-8,0,0,0,0\n",
            "44,113,18,89,72\n",
            "12,-60,-35,22,-19\n",
            "0,0,-5,0,-5\n",
            "44,11,94,71,105\n",
            "9,-9,20,-5,0\n",
            "-35,82,43,121,84\n",
            "-50,-42,-31,17,21\n",
            "-34,13,-33,-1,-31\n",
            "-10,0,-13,-1,-11\n",
            "\n",
            "Layer Two Weights (comma-separated):\n",
            "90,33,0,-38,-37,77,11,9,-18,-26,0,-49,76,0,24,0,11,62,63,0\n",
            "-59,24,9,61,110,-40,8,0,47,82,0,12,-110,0,89,-8,-11,-60,-96,0\n",
            "0,0,0,6,0,10,-2,-3,4,-4,0,-2,0,0,0,0,0,1,0,-2\n",
            "-47,38,11,94,94,-57,31,0,100,86,0,95,-92,0,27,11,26,-121,-50,0\n",
            "1,-5,0,-1,0,5,0,0,5,0,10,-17,17,0,0,1,12,-3,-2,0\n",
            "-38,-31,3,22,45,-36,43,7,46,13,0,47,-44,0,22,-1,-5,-43,-38,2\n",
            "0,0,0,-4,-8,0,0,5,0,0,-8,0,0,0,0,3,0,0,0,0\n",
            "75,36,-6,-91,-95,127,-66,-2,-17,-66,0,-11,83,-1,-95,0,43,124,115,0\n",
            "-35,-17,0,3,26,-23,84,0,42,69,0,45,-61,-2,75,9,96,-21,-53,-7\n",
            "54,55,0,-79,-37,50,-79,-9,-107,73,-5,-66,57,0,90,0,109,41,101,1\n",
            "\n",
            "Layer Three Weights (comma-separated):\n",
            "92,-90,-21,-96,0,-17,0,116,-112,59\n",
            "-6,-39,0,-51,30,-45,0,-117,102,127\n",
            "-64,113,-20,65,0,45,0,-73,83,-110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_fixed_point_multiplier(input_scale, weight_scale, output_scale):\n",
        "    # Calculate M0 and N from M = 2^-N M0 = (S1 * S2 / S3)\n",
        "    multiplier = input_scale * weight_scale / output_scale\n",
        "    shift = 0\n",
        "    while multiplier < 0.5:\n",
        "        multiplier *= 2\n",
        "        shift += 1\n",
        "    quantized_multiplier = multiplier * math.pow(2, 31)\n",
        "    return quantized_multiplier, shift"
      ],
      "metadata": {
        "id": "l00b5QnEaRmX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First layer requantization params\n",
        "layer_one_multiplier, layer_one_shift = calculate_fixed_point_multiplier(input_layer_scale, layer_one_weights_scale, layer_one_output_activations_scale)\n",
        "\n",
        "# Second layer requantization params\n",
        "layer_two_multiplier, layer_two_shift = calculate_fixed_point_multiplier(layer_one_output_activations_scale, layer_two_weights_scale, output_layer_scale)\n",
        "\n",
        "# Third layer requantization params\n",
        "layer_three_multiplier, layer_three_shift = calculate_fixed_point_multiplier(layer_two_output_activations_scale, layer_three_weights_scale, output_layer_scale)\n",
        "\n",
        "subscript_printing = str.maketrans(\"123456789\", \"₁₂₃₄₅₆₇₈₉\")\n",
        "print(\"Layer 1 Requantization Params:\")\n",
        "print(\"M01: \".translate(subscript_printing) + f\"{layer_one_multiplier[0]:.2f}\")\n",
        "print(\"N1: \".translate(subscript_printing)  + f\"{layer_one_shift}\")\n",
        "\n",
        "print(\"Layer 2 Requantization Params:\")\n",
        "print(\"M02: \".translate(subscript_printing) + f\"{layer_two_multiplier[0]:.2f}\")\n",
        "print(\"N2: \".translate(subscript_printing)  + f\"{layer_two_shift}\")\n",
        "\n",
        "print(\"Layer 3 Requantization Params:\")\n",
        "print(\"M03: \".translate(subscript_printing) + f\"{layer_three_multiplier[0]:.2f}\")\n",
        "print(\"N3: \".translate(subscript_printing)  + f\"{layer_three_shift}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibGduAd2bMYE",
        "outputId": "b722acb1-6292-488c-d780-e93a22985860"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Requantization Params:\n",
            "M0₁: 1428873344.00\n",
            "N₁: 8\n",
            "Layer 2 Requantization Params:\n",
            "M0₂: 1890307072.00\n",
            "N₂: 10\n",
            "Layer 3 Requantization Params:\n",
            "M0₃: 1217779456.00\n",
            "N₃: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Emulate 8-bit Integer Inference with Numpy**"
      ],
      "metadata": {
        "id": "pDmEYHIJoB5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create copy of test dataset\n",
        "TEST_SET_SIZE = 45\n",
        "test_dataset_copy = (iter(test_dataset_quantized_inputs.take(TEST_SET_SIZE)))"
      ],
      "metadata": {
        "id": "Sskn2QitsQ1e"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_tflite_golden_inference(tflite_model, inputs, debug=False):\n",
        "    #\n",
        "    # Golden Reference Implementation of TFLite Inference running on a single sample\n",
        "    #\n",
        "\n",
        "    # Add batch dim to single data sample\n",
        "    inputs = np.expand_dims(inputs, 0)\n",
        "\n",
        "    # Load TFLite model and allocate tensors\n",
        "    interpreter = tf.lite.Interpreter(model_content=tflite_model, experimental_preserve_all_tensors=True)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input and output tensors\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Load input tensor\n",
        "    interpreter.set_tensor(input_details[0]['index'], inputs)\n",
        "\n",
        "    # Run the model\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Print each layer's output if needed for verification\n",
        "    if debug:\n",
        "      print({\n",
        "          t['name']: interpreter.get_tensor(t['index'])\n",
        "          for t in interpreter.get_tensor_details()\n",
        "      })\n",
        "\n",
        "    return interpreter.get_tensor(output_details[0]['index'])"
      ],
      "metadata": {
        "id": "jja_F8B4sRqV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_numpy_inference(input):\n",
        "  #\n",
        "  # Numpy Reference Implementation of TFLite Inference running on a single sample\n",
        "  #\n",
        "\n",
        "  # (Inputs * Layer 1 Weights) + Bias followed by ReLU\n",
        "  x = np.matmul((input.numpy().astype(np.int32) - input_layer_zero_point.astype(np.int32)),(layer_one_weights.T.astype(np.int32) - layer_one_weights_zero_point.astype(np.int32)))\n",
        "  x = x + layer_one_bias\n",
        "  x = np.maximum(x, 0)\n",
        "\n",
        "  # Requantization pipeline\n",
        "  x = x * layer_one_multiplier\n",
        "  x = np.round((x / np.power(2,31))).astype(np.int32)\n",
        "  x = np.round((x / np.power(2, layer_one_shift))).astype(np.int32)\n",
        "  x = x + layer_one_output_activations_zero_point.astype(np.int32)\n",
        "  x = np.clip(x, -128, 127)\n",
        "\n",
        "  # (Layer 1 Activations * Layer 2 Weights) + Bias\n",
        "  x = np.matmul((x.astype(np.int32) - layer_one_output_activations_zero_point.astype(np.int32)), (layer_two_weights.T.astype(np.int32) - layer_two_weights_zero_point.astype(np.int32)))\n",
        "  x = x + layer_two_bias\n",
        "\n",
        "  # Requantization pipeline\n",
        "  x = x * layer_two_multiplier\n",
        "  x = np.round((x / np.power(2,31))).astype(np.int32)\n",
        "  x = np.round((x / np.power(2, layer_two_shift))).astype(np.int32)\n",
        "  x = x + layer_two_output_activations_zero_point.astype(np.int32)\n",
        "  x = np.clip(x, -128, 127)\n",
        "\n",
        "  # (Layer 2 Activations * Layer 2 Weights) + Bias\n",
        "  x = np.matmul((x.astype(np.int32) - layer_two_output_activations_zero_point.astype(np.int32)), (layer_three_weights.T.astype(np.int32) - layer_three_weights_zero_point.astype(np.int32)))\n",
        "  x = x + layer_three_bias\n",
        "\n",
        "  # Requantization pipeline\n",
        "  x = x * layer_three_multiplier\n",
        "  x = np.round((x / np.power(2,31))).astype(np.int32)\n",
        "  x = np.round((x / np.power(2, layer_two_shift))).astype(np.int32)\n",
        "  x = x + output_layer_zero_point.astype(np.int32)\n",
        "  x = np.clip(x, -128, 127)\n",
        "\n",
        "  return x\n"
      ],
      "metadata": {
        "id": "5_Hx0jC7oBje"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_correct = 0.0\n",
        "numpy_correct = 0.0\n",
        "\n",
        "for inputs, targets in test_dataset_copy:\n",
        "  tflite_output = run_tflite_golden_inference(tflite_quant_model, inputs)\n",
        "  numpy_output = run_numpy_inference(inputs)\n",
        "\n",
        "  # Make sure that raw values of output tensors match exactly to validate numpy reference implementation\n",
        "  if np.array_equal(tflite_output.flatten()[0], numpy_output.flatten()):\n",
        "    print(tflite_output)\n",
        "    print(numpy_output)\n",
        "    print(\"ERROR: TFlite Golden Output Tensor does not match Numpy Implementation Output Tensor\")\n",
        "\n",
        "  # Update num correct\n",
        "  if tflite_output.argmax() == targets.numpy():\n",
        "    tflite_correct += 1\n",
        "  if numpy_output.argmax() == targets.numpy():\n",
        "    numpy_correct += 1\n",
        "\n",
        "\n",
        "\n",
        "# Make sure accuracy is exactly the same to validate numpy implementation\n",
        "print(f\"TF Lite Accuracy: {tflite_correct / TEST_SET_SIZE}\")\n",
        "print(f\"Numpy Accuracy: {numpy_correct / TEST_SET_SIZE}\")\n",
        "print(\"Numpy Implementation matches TFLite Golden Implementation!\" if tflite_correct / TEST_SET_SIZE == numpy_correct / TEST_SET_SIZE else \"Numpy Implementation does NOT match TFLite Golden Implementation...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1qDAzufb-ZD",
        "outputId": "198dcba3-3709-45c0-f536-644161d9a21c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Lite Accuracy: 1.0\n",
            "Numpy Accuracy: 1.0\n",
            "Numpy Implementation matches TFLite Golden Implementation!\n"
          ]
        }
      ]
    }
  ]
}