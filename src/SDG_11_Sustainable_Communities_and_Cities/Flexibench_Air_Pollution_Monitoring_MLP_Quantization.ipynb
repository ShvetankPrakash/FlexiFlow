{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **FlexiBench Air Quality & Pollution Monitoring MLP Quantization**\n",
        "### Author: Shvetank Prakash\n",
        "### Date: Jan 2025\n",
        "#### Dataset: [UCI Air Quality](https://archive.ics.uci.edu/dataset/360/air+quality)\n",
        "#### Helpful links:\n",
        "\n",
        "[Air Quality Index and Air Pollutant Concentration\n",
        "Prediction Based on Machine Learning Algorithms](https://www.mdpi.com/2076-3417/9/19/4069) (Paper Results Modeled)\n",
        "\n",
        "[Using neural networks for short-term prediction of air pollution levels\n",
        "](https://ieeexplore.ieee.org/document/5227910) (Similar Application/Implementation)\n",
        "\n",
        "\n",
        "[Waste Management and Prediction of Air Pollutants\n",
        "Using IoT and Machine Learning Approach](https://www.mdpi.com/1996-1073/13/15/3930) (Similar Application/Implementation)\n",
        "\n",
        "[Gemmlowp Paper](https://arxiv.org/pdf/1712.05877)\n",
        "\n",
        "[Gemmlowp Implementation](https://github.com/google/gemmlowp/tree/master)\n"
      ],
      "metadata": {
        "id": "B6xKk1RMw3zG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Imports and Global Defs"
      ],
      "metadata": {
        "id": "zmARXYN5xetM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-model-optimization==0.8.0\n",
        "!pip install ucimlrepo==0.0.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-7RwFYPOH7xC",
        "outputId": "6bda9706-c664-4658-b4a9-8aa1b01df4a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-model-optimization==0.8.0\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization==0.8.0) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization==0.8.0) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization==0.8.0) (1.26.4)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization==0.8.0) (1.17.0)\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.8.0\n",
            "Collecting ucimlrepo==0.0.7\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo==0.0.7) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo==0.0.7) (2024.12.14)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo==0.0.7) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo==0.0.7) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo==0.0.7) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo==0.0.7) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo==0.0.7) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import math\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Setting environment variables\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8tYezt7xmzUa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Parameters\n",
        "INPUT_SIZE = 2\n",
        "HIDDEN_SIZE = 32\n",
        "OUTPUT_SIZE = 1\n",
        "\n",
        "# Training Parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE_TRAIN = 32\n",
        "BATCH_SIZE_TEST = 32\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "fMfZ9zYJIdCK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Read and Preprocess Dataset**\n",
        "\n",
        "***Download Dataset from Kaggle [here](https://www.kaggle.com/datasets/fedesoriano/air-quality-data-set) and place in file directory of this notebook. As noted on the Kaggle page link, this dataset comes from the UCI ML Repository [here](https://archive.ics.uci.edu/dataset/360/air+quality).***"
      ],
      "metadata": {
        "id": "2Jml3fzQBpSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# # Fetch dataset\n",
        "# air_quality = fetch_ucirepo(id=360)\n",
        "\n",
        "# # Data (as pandas dataframes)\n",
        "# data = air_quality.data.original[['CO(GT)', 'NOx(GT)', 'NO2(GT)']].astype('float32')  # select only the relevant columns"
      ],
      "metadata": {
        "id": "62BZTsvaflYq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset downloaded from Kaggle link above (adopted from UCI ML Repository)\n",
        "data = pd.read_csv('AirQuality.csv', delimiter=';', decimal=',')\n",
        "data.columns = data.columns.str.strip()\n",
        "data = data[['CO(GT)', 'NOx(GT)', 'NO2(GT)', 'PT08.S5(O3)', 'NMHC(GT)']]  # select only some columns based on correlation matrix from: https://www.mdpi.com/2076-3417/9/19/4069\n",
        "data = data.dropna() # drop any rows with missing values\n",
        "data = data[(data >= 0).all(axis=1)]  # remove rows with negative values in any of the selected columns\n",
        "\n",
        "# Function to quantize data to uint8\n",
        "def normalize(series):\n",
        "    min_val = series.min()\n",
        "    max_val = series.max()\n",
        "    scaled = (series - min_val) / (max_val - min_val)\n",
        "    return scaled\n",
        "\n",
        "# Apply the normalization to all numeric columns\n",
        "numeric_columns = data.select_dtypes(include=[np.number]).columns\n",
        "data[numeric_columns] = data[numeric_columns].apply(normalize)\n",
        "\n",
        "# Save the quantized dataset to a new CSV file\n",
        "data.to_csv('Normalized_AirQuality.csv', index=False)\n"
      ],
      "metadata": {
        "id": "a8fYNjKBd583"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'Normalized_AirQuality.csv'  # read the quantized dataset for training\n",
        "data = pd.read_csv(data_path, delimiter=',')\n",
        "data = data[['CO(GT)', 'NOx(GT)', 'NO2(GT)']].astype('float32')  # select only the relevant columns\n",
        "\n",
        "data = data.dropna()  # Drop any rows with missing values\n",
        "data = data[(data >= 0).all(axis=1)]  # remove rows with negative values in any of the selected columns\n",
        "# Note: we do not normalize column values between 0 and 1 for training as we empirically observe better training results when training directly on quantized uint8 data\n",
        "\n",
        "# Predict NOx concentration from CO and NO2\n",
        "X = data[['CO(GT)', 'NO2(GT)']].values\n",
        "y = data['NOx(GT)'].values\n",
        "\n",
        "# Split the data using train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)  # adjust test_size and random_state as needed\n",
        "\n",
        "# Create tf.data.Dataset objects\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "# Batch the datasets\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(X_train), seed=SEED).batch(BATCH_SIZE_TRAIN)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE_TEST)"
      ],
      "metadata": {
        "id": "YJ_KJE3dn4kd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print one sample from train and test dataset each\n",
        "print(\"Train Dataset Sample:\")\n",
        "for x, y in train_dataset.take(1):\n",
        "    print(f\"Inputs: {x}\")\n",
        "    print(f\"Output:  {y}\")\n",
        "\n",
        "print(\"Test Dataset Sample:\")\n",
        "for x, y in test_dataset.take(1):\n",
        "    print(f\"Inputs: {x}\")\n",
        "    print(f\"Output:  {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceLFqDdGNIjv",
        "outputId": "6e9edea9-5a62-48fc-f825-c77fb5388695"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Sample:\n",
            "Inputs: [[0.20512821 0.42937854]\n",
            " [0.07692308 0.15254237]\n",
            " [0.14102565 0.40677965]\n",
            " [0.12820514 0.32768363]\n",
            " [0.23076923 0.47457626]\n",
            " [0.21794872 0.33898306]\n",
            " [0.2820513  0.53672314]\n",
            " [0.05128205 0.2937853 ]\n",
            " [0.15384616 0.34463277]\n",
            " [0.16666667 0.46327683]\n",
            " [0.07692308 0.2259887 ]\n",
            " [0.2820513  0.56497175]\n",
            " [0.35897437 0.46892655]\n",
            " [0.51282054 0.66101694]\n",
            " [0.35897437 0.4519774 ]\n",
            " [0.25641027 0.4858757 ]\n",
            " [0.2948718  0.45762712]\n",
            " [0.32051283 0.5141243 ]\n",
            " [0.1923077  0.40112993]\n",
            " [0.08974359 0.2937853 ]\n",
            " [0.11538462 0.2881356 ]\n",
            " [0.02564103 0.09039548]\n",
            " [0.17948718 0.50282484]\n",
            " [0.14102565 0.3220339 ]\n",
            " [0.55128205 0.7175141 ]\n",
            " [0.17948718 0.31638417]\n",
            " [0.41025642 0.5141243 ]\n",
            " [0.6025641  0.70621467]\n",
            " [0.14102565 0.3220339 ]\n",
            " [0.4871795  0.50282484]\n",
            " [0.20512821 0.36158192]\n",
            " [0.7948718  0.7175141 ]]\n",
            "Output:  [0.20171674 0.06437768 0.14377682 0.15879828 0.24678111 0.16309012\n",
            " 0.26824033 0.08583691 0.18025751 0.16523606 0.09656652 0.29613733\n",
            " 0.3025751  0.472103   0.34120172 0.2553648  0.2918455  0.31759655\n",
            " 0.1695279  0.10515022 0.15665236 0.02575107 0.2274678  0.21459228\n",
            " 0.46781117 0.19098713 0.37124464 0.53004295 0.14806867 0.6609442\n",
            " 0.19527897 0.6866953 ]\n",
            "Test Dataset Sample:\n",
            "Inputs: [[0.12820514 0.37853107]\n",
            " [0.02564103 0.11299435]\n",
            " [0.11538462 0.33333334]\n",
            " [0.26923078 0.46892655]\n",
            " [0.2948718  0.47457626]\n",
            " [0.15384616 0.4915254 ]\n",
            " [0.2948718  0.5084746 ]\n",
            " [0.33333334 0.6158192 ]\n",
            " [0.30769232 0.4463277 ]\n",
            " [0.1025641  0.28248587]\n",
            " [0.25641027 0.4519774 ]\n",
            " [0.17948718 0.49717513]\n",
            " [0.33333334 0.5762712 ]\n",
            " [0.4871795  0.6497175 ]\n",
            " [0.14102565 0.40677965]\n",
            " [0.20512821 0.46327683]\n",
            " [0.1025641  0.4463277 ]\n",
            " [0.30769232 0.47457626]\n",
            " [0.525641   0.5141243 ]\n",
            " [0.2948718  0.55932206]\n",
            " [0.3846154  0.5762712 ]\n",
            " [0.2820513  0.59322035]\n",
            " [0.24358974 0.4915254 ]\n",
            " [0.25641027 0.46892655]\n",
            " [0.16666667 0.40112993]\n",
            " [0.14102565 0.33898306]\n",
            " [0.74358976 0.8079096 ]\n",
            " [0.2820513  0.5819209 ]\n",
            " [0.01282051 0.03389831]\n",
            " [0.35897437 0.53672314]\n",
            " [0.21794872 0.49717513]\n",
            " [0.05128205 0.11299435]]\n",
            "Output:  [0.1416309  0.03648069 0.13519314 0.25751072 0.27038628 0.18669528\n",
            " 0.4356223  0.36051503 0.23175965 0.13733906 0.25965664 0.25751072\n",
            " 0.2746781  0.53004295 0.1502146  0.2274678  0.21244635 0.3304721\n",
            " 0.47854078 0.3197425  0.37124464 0.27038628 0.2446352  0.23390558\n",
            " 0.25751072 0.10300429 0.64806867 0.2639485  0.01072961 0.37768242\n",
            " 0.21030043 0.027897  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Model**"
      ],
      "metadata": {
        "id": "dSBlaBAaAYEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mlp(input_size, hidden_size, output_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.InputLayer(input_shape=(input_size,)),\n",
        "        layers.Dense(hidden_size, activation='relu'),\n",
        "        layers.Dense(output_size)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = create_mlp(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
        "opt = Adam(learning_rate=LEARNING_RATE, beta_1=0.9, beta_2=0.999)\n",
        "model.compile(optimizer=opt, loss='mean_squared_error', metrics=['mae'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "RTuXXZnTKVJ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "f1b8712c-ebee-40ad-d5ed-c273f9ea92d5",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │              \u001b[38;5;34m96\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m129\u001b[0m (516.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> (516.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129\u001b[0m (516.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> (516.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train from Scratch in FP32**"
      ],
      "metadata": {
        "id": "OSfrYoT5_vc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial non-quant training\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_dataset\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "trLEGuB-ItPp",
        "outputId": "7311bbfa-47fd-4643-b0c2-0f96738cce32"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0356 - mae: 0.1409 - val_loss: 0.0147 - val_mae: 0.0864\n",
            "Epoch 2/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0818 - val_loss: 0.0092 - val_mae: 0.0820\n",
            "Epoch 3/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0095 - mae: 0.0810 - val_loss: 0.0066 - val_mae: 0.0689\n",
            "Epoch 4/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0629 - val_loss: 0.0048 - val_mae: 0.0569\n",
            "Epoch 5/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0553 - val_loss: 0.0035 - val_mae: 0.0463\n",
            "Epoch 6/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0431 - val_loss: 0.0029 - val_mae: 0.0420\n",
            "Epoch 7/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031 - mae: 0.0423 - val_loss: 0.0026 - val_mae: 0.0388\n",
            "Epoch 8/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0403 - val_loss: 0.0026 - val_mae: 0.0381\n",
            "Epoch 9/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0026 - val_mae: 0.0385\n",
            "Epoch 10/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0030 - mae: 0.0395 - val_loss: 0.0025 - val_mae: 0.0370\n",
            "Epoch 11/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0389 - val_loss: 0.0025 - val_mae: 0.0373\n",
            "Epoch 12/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0028 - mae: 0.0377 - val_loss: 0.0025 - val_mae: 0.0367\n",
            "Epoch 13/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0373 - val_loss: 0.0026 - val_mae: 0.0364\n",
            "Epoch 14/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0388 - val_loss: 0.0025 - val_mae: 0.0367\n",
            "Epoch 15/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0368 - val_loss: 0.0027 - val_mae: 0.0404\n",
            "Epoch 16/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0387 - val_loss: 0.0026 - val_mae: 0.0386\n",
            "Epoch 17/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - mae: 0.0370 - val_loss: 0.0026 - val_mae: 0.0363\n",
            "Epoch 18/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0355 - val_loss: 0.0026 - val_mae: 0.0392\n",
            "Epoch 19/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0027 - mae: 0.0387 - val_loss: 0.0025 - val_mae: 0.0367\n",
            "Epoch 20/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0028 - mae: 0.0394 - val_loss: 0.0026 - val_mae: 0.0364\n",
            "Epoch 21/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - mae: 0.0376 - val_loss: 0.0025 - val_mae: 0.0380\n",
            "Epoch 22/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 - mae: 0.0398 - val_loss: 0.0025 - val_mae: 0.0368\n",
            "Epoch 23/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0365 - val_loss: 0.0027 - val_mae: 0.0399\n",
            "Epoch 24/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0418 - val_loss: 0.0025 - val_mae: 0.0370\n",
            "Epoch 25/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0375 - val_loss: 0.0026 - val_mae: 0.0363\n",
            "Epoch 26/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0385 - val_loss: 0.0025 - val_mae: 0.0372\n",
            "Epoch 27/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0372 - val_loss: 0.0025 - val_mae: 0.0372\n",
            "Epoch 28/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0030 - mae: 0.0390 - val_loss: 0.0026 - val_mae: 0.0387\n",
            "Epoch 29/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0029 - mae: 0.0389 - val_loss: 0.0025 - val_mae: 0.0377\n",
            "Epoch 30/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0387 - val_loss: 0.0025 - val_mae: 0.0374\n",
            "Epoch 31/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0393 - val_loss: 0.0025 - val_mae: 0.0368\n",
            "Epoch 32/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - mae: 0.0370 - val_loss: 0.0026 - val_mae: 0.0390\n",
            "Epoch 33/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0375 - val_loss: 0.0025 - val_mae: 0.0379\n",
            "Epoch 34/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0355 - val_loss: 0.0025 - val_mae: 0.0370\n",
            "Epoch 35/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - mae: 0.0396 - val_loss: 0.0026 - val_mae: 0.0390\n",
            "Epoch 36/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0386 - val_loss: 0.0027 - val_mae: 0.0364\n",
            "Epoch 37/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0391 - val_loss: 0.0026 - val_mae: 0.0364\n",
            "Epoch 38/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - mae: 0.0391 - val_loss: 0.0026 - val_mae: 0.0364\n",
            "Epoch 39/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032 - mae: 0.0405 - val_loss: 0.0025 - val_mae: 0.0371\n",
            "Epoch 40/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0384 - val_loss: 0.0025 - val_mae: 0.0379\n",
            "Epoch 41/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0030 - mae: 0.0389 - val_loss: 0.0025 - val_mae: 0.0374\n",
            "Epoch 42/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0373 - val_loss: 0.0025 - val_mae: 0.0370\n",
            "Epoch 43/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0389 - val_loss: 0.0025 - val_mae: 0.0375\n",
            "Epoch 44/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0374 - val_loss: 0.0026 - val_mae: 0.0400\n",
            "Epoch 45/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0377 - val_loss: 0.0025 - val_mae: 0.0372\n",
            "Epoch 46/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0364 - val_loss: 0.0025 - val_mae: 0.0376\n",
            "Epoch 47/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0394 - val_loss: 0.0026 - val_mae: 0.0388\n",
            "Epoch 48/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0383 - val_loss: 0.0025 - val_mae: 0.0387\n",
            "Epoch 49/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0028 - mae: 0.0383 - val_loss: 0.0025 - val_mae: 0.0380\n",
            "Epoch 50/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0399 - val_loss: 0.0025 - val_mae: 0.0370\n",
            "Epoch 51/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - mae: 0.0390 - val_loss: 0.0025 - val_mae: 0.0363\n",
            "Epoch 52/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - mae: 0.0389 - val_loss: 0.0025 - val_mae: 0.0365\n",
            "Epoch 53/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0363 - val_loss: 0.0025 - val_mae: 0.0379\n",
            "Epoch 54/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - mae: 0.0403 - val_loss: 0.0026 - val_mae: 0.0361\n",
            "Epoch 55/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026 - mae: 0.0374 - val_loss: 0.0025 - val_mae: 0.0375\n",
            "Epoch 56/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0027 - mae: 0.0372 - val_loss: 0.0025 - val_mae: 0.0371\n",
            "Epoch 57/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0032 - mae: 0.0398 - val_loss: 0.0025 - val_mae: 0.0363\n",
            "Epoch 58/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0030 - mae: 0.0402 - val_loss: 0.0025 - val_mae: 0.0371\n",
            "Epoch 59/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0397 - val_loss: 0.0025 - val_mae: 0.0366\n",
            "Epoch 60/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0370 - val_loss: 0.0025 - val_mae: 0.0372\n",
            "Epoch 61/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0356 - val_loss: 0.0025 - val_mae: 0.0378\n",
            "Epoch 62/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0368 - val_loss: 0.0025 - val_mae: 0.0373\n",
            "Epoch 63/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0386 - val_loss: 0.0025 - val_mae: 0.0379\n",
            "Epoch 64/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0367 - val_loss: 0.0025 - val_mae: 0.0358\n",
            "Epoch 65/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0025 - val_mae: 0.0361\n",
            "Epoch 66/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0364 - val_loss: 0.0025 - val_mae: 0.0374\n",
            "Epoch 67/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0372 - val_loss: 0.0025 - val_mae: 0.0377\n",
            "Epoch 68/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0369 - val_loss: 0.0025 - val_mae: 0.0374\n",
            "Epoch 69/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - mae: 0.0353 - val_loss: 0.0026 - val_mae: 0.0397\n",
            "Epoch 70/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0028 - mae: 0.0400 - val_loss: 0.0024 - val_mae: 0.0365\n",
            "Epoch 71/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0028 - mae: 0.0385 - val_loss: 0.0025 - val_mae: 0.0358\n",
            "Epoch 72/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0367 - val_loss: 0.0025 - val_mae: 0.0385\n",
            "Epoch 73/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0361 - val_loss: 0.0024 - val_mae: 0.0374\n",
            "Epoch 74/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0402 - val_loss: 0.0024 - val_mae: 0.0370\n",
            "Epoch 75/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - mae: 0.0359 - val_loss: 0.0024 - val_mae: 0.0363\n",
            "Epoch 76/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0376 - val_loss: 0.0024 - val_mae: 0.0363\n",
            "Epoch 77/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0370 - val_loss: 0.0024 - val_mae: 0.0363\n",
            "Epoch 78/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0368 - val_loss: 0.0025 - val_mae: 0.0358\n",
            "Epoch 79/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0336 - val_loss: 0.0026 - val_mae: 0.0398\n",
            "Epoch 80/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0029 - mae: 0.0399 - val_loss: 0.0025 - val_mae: 0.0385\n",
            "Epoch 81/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0362 - val_loss: 0.0026 - val_mae: 0.0410\n",
            "Epoch 82/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0029 - mae: 0.0397 - val_loss: 0.0025 - val_mae: 0.0359\n",
            "Epoch 83/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0025 - mae: 0.0366 - val_loss: 0.0025 - val_mae: 0.0359\n",
            "Epoch 84/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0027 - mae: 0.0375 - val_loss: 0.0024 - val_mae: 0.0361\n",
            "Epoch 85/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0388 - val_loss: 0.0024 - val_mae: 0.0359\n",
            "Epoch 86/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0351 - val_loss: 0.0025 - val_mae: 0.0379\n",
            "Epoch 87/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0027 - mae: 0.0378 - val_loss: 0.0024 - val_mae: 0.0363\n",
            "Epoch 88/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0026 - mae: 0.0375 - val_loss: 0.0024 - val_mae: 0.0360\n",
            "Epoch 89/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0027 - mae: 0.0378 - val_loss: 0.0025 - val_mae: 0.0358\n",
            "Epoch 90/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0029 - mae: 0.0382 - val_loss: 0.0026 - val_mae: 0.0361\n",
            "Epoch 91/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0385 - val_loss: 0.0024 - val_mae: 0.0361\n",
            "Epoch 92/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0362 - val_loss: 0.0024 - val_mae: 0.0367\n",
            "Epoch 93/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0358 - val_loss: 0.0024 - val_mae: 0.0366\n",
            "Epoch 94/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0025 - mae: 0.0374 - val_loss: 0.0024 - val_mae: 0.0361\n",
            "Epoch 95/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - mae: 0.0385 - val_loss: 0.0024 - val_mae: 0.0375\n",
            "Epoch 96/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0029 - mae: 0.0397 - val_loss: 0.0024 - val_mae: 0.0370\n",
            "Epoch 97/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0026 - mae: 0.0371 - val_loss: 0.0024 - val_mae: 0.0368\n",
            "Epoch 98/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0380 - val_loss: 0.0024 - val_mae: 0.0364\n",
            "Epoch 99/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0405 - val_loss: 0.0024 - val_mae: 0.0358\n",
            "Epoch 100/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0395 - val_loss: 0.0024 - val_mae: 0.0364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vizualize Training History**"
      ],
      "metadata": {
        "id": "17dCr9zgAnQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "BpMKkmkDmweF",
        "outputId": "506e8f0f-4a3c-48ae-fb2d-db8b21476785",
        "collapsed": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Set Classification Accuracy of FP32 Model**"
      ],
      "metadata": {
        "id": "egHE_K6vArh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the FP32 model\n",
        "results = model.evaluate(test_dataset)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Test Loss: {results[0]}, Test MAE: {results[1]}\")\n",
        "\n",
        "# Predict 1 hour ahead on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate R² score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'\\nR² score: {r2}')\n",
        "\n",
        "# Goal: Target R2 >= 0.88"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IElgrf-TJJPC",
        "outputId": "fa841b92-d38e-4f76-ac68-6af950f150e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mae: 0.0354 \n",
            "Test Loss: 0.002396773546934128, Test MAE: 0.03636900708079338\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\n",
            "R² score: 0.9235679507255554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convert to TFLite Model**"
      ],
      "metadata": {
        "id": "tdyvZiHWA-A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "# Print tensor details\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "for tensor in interpreter.get_tensor_details():\n",
        "    print(tensor['name'], tensor['dtype'])\n",
        "    try:\n",
        "        # Attempt to get tensor data\n",
        "        tensor_data = interpreter.get_tensor(tensor['index'])\n",
        "        print(tensor_data)\n",
        "    except ValueError:\n",
        "        # Skip tensors with null data\n",
        "        print(f\"Skipping tensor '{tensor['name']}' as it has null data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC6reRpb_00G",
        "outputId": "20732e5c-a846-48e6-9219-ffbf3a4b817e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpu7507xqn'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 2), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134638545261328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134638545262096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134638545261136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134638545263248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "serving_default_keras_tensor:0 <class 'numpy.float32'>\n",
            "[[4.9128376e-32 0.0000000e+00]]\n",
            "arith.constant <class 'numpy.float32'>\n",
            "[[ 0.5478622   0.06143686  0.22692907  0.32726082  0.27761656 -0.45524037\n",
            "   0.2241812  -0.17943075 -0.3651709  -0.18907689 -0.23554206  0.01485139\n",
            "   0.14334978  0.11927134  0.04392979 -0.39882535  0.20080668  0.28984806\n",
            "  -0.30226865  0.053534    0.23917842  0.53367776  0.0925779   0.39441562\n",
            "   0.20832723  0.30796242 -0.02950111 -0.24658704  0.14428519  0.02480774\n",
            "  -0.215641    0.09021159]]\n",
            "sequential_1/dense_1_2/Add/ReadVariableOp <class 'numpy.float32'>\n",
            "[0.01306049]\n",
            "sequential_1/dense_1/Add/ReadVariableOp <class 'numpy.float32'>\n",
            "[ 0.05076974 -0.00938202  0.          0.05609183 -0.044878    0.14775185\n",
            "  0.00936875  0.12262636  0.         -0.07038046  0.          0.\n",
            "  0.00712961  0.         -0.00357235 -0.0178513   0.         -0.01981293\n",
            " -0.03622757 -0.00488316  0.          0.0500506   0.00228067  0.01147239\n",
            "  0.00841251  0.          0.          0.          0.00751262  0.00030474\n",
            "  0.          0.00146145]\n",
            "sequential_1/dense_1/MatMul <class 'numpy.float32'>\n",
            "[[ 0.37619266 -0.2788472 ]\n",
            " [ 0.19803216 -0.04026907]\n",
            " [-0.1187067  -0.19736509]\n",
            " [ 0.47624397 -0.23493364]\n",
            " [-0.2687153   0.25520363]\n",
            " [-0.06054433 -0.20600872]\n",
            " [ 0.46073812  0.18712811]\n",
            " [-0.34917474  0.06621723]\n",
            " [ 0.01998699 -0.384267  ]\n",
            " [ 0.11080304  0.02526656]\n",
            " [-0.34747815 -0.13936564]\n",
            " [-0.04506871 -0.09506771]\n",
            " [ 0.45891175  0.41663295]\n",
            " [-0.02491847 -0.07528403]\n",
            " [ 0.10017643  0.05972709]\n",
            " [ 0.19477445 -0.24004948]\n",
            " [-0.4042637  -0.31689698]\n",
            " [-0.2219688   0.21367256]\n",
            " [-0.02800692  0.05969765]\n",
            " [-0.3642761   0.00356858]\n",
            " [-0.38845593 -0.39675933]\n",
            " [ 0.3766891  -0.26053768]\n",
            " [ 0.4217612   0.2800334 ]\n",
            " [-0.13707383  0.3422351 ]\n",
            " [ 0.36900148 -0.02228479]\n",
            " [-0.312984   -0.15647367]\n",
            " [-0.0316866  -0.39230943]\n",
            " [ 0.05269688 -0.38757566]\n",
            " [ 0.12225787  0.25213182]\n",
            " [-0.18816502  0.3062907 ]\n",
            " [-0.2439069  -0.10419652]\n",
            " [ 0.48528582  0.21999957]]\n",
            "sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/Add <class 'numpy.float32'>\n",
            "Skipping tensor 'sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/Add' as it has null data.\n",
            "StatefulPartitionedCall_1:0 <class 'numpy.float32'>\n",
            "[[0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convert to Quantized Model**"
      ],
      "metadata": {
        "id": "C1gaSy-8xaMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide a representative dataset to guide the quantization process\n",
        "def representative_dataset_gen():\n",
        "    for data, _ in test_dataset.unbatch().batch(1).take(100):\n",
        "        yield [data]\n",
        "\n",
        "# Convert the model to int8 format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "converter.experimental_new_quantizer = False  # Optional: Use the default quantizer\n",
        "converter._experimental_disable_per_channel = True\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "# Save the model\n",
        "with open('model_quantized.tflite', 'wb') as f:\n",
        "  f.write(tflite_quant_model)\n",
        "\n",
        "# Print tensor details\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "for tensor in interpreter.get_tensor_details():\n",
        "    print(tensor['name'], tensor['dtype'])\n",
        "    try:\n",
        "        # Attempt to get tensor data\n",
        "        tensor_data = interpreter.get_tensor(tensor['index'])\n",
        "        print(tensor_data)\n",
        "    except ValueError:\n",
        "        # Skip tensors with null data\n",
        "        print(f\"Skipping tensor '{tensor['name']}' as it has null data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu50RF1HBJZ_",
        "outputId": "93bc0848-282c-42c5-bda6-69df2116f46f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpbieevelh'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 2), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134638545261328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134638545262096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134638545261136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134638545263248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:983: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "serving_default_keras_tensor:0_int8 <class 'numpy.int8'>\n",
            "[[-32  60]]\n",
            "arith.constant <class 'numpy.int8'>\n",
            "[[ 127   14   53   76   64 -106   52  -42  -85  -44  -55    3   33   28\n",
            "    10  -92   47   67  -70   12   55  124   21   91   48   71   -7  -57\n",
            "    33    6  -50   21]]\n",
            "sequential_1/dense_1_2/Add/ReadVariableOp <class 'numpy.int32'>\n",
            "[1006]\n",
            "sequential_1/dense_1/Add/ReadVariableOp <class 'numpy.int32'>\n",
            "[ 3679  -680     0  4065 -3252 10707   679  8886     0 -5100     0     0\n",
            "   517     0  -259 -1294     0 -1436 -2625  -354     0  3627   165   831\n",
            "   610     0     0     0   544    22     0   106]\n",
            "sequential_1/dense_1/MatMul <class 'numpy.int8'>\n",
            "[[  98  -73]\n",
            " [  52  -11]\n",
            " [ -31  -52]\n",
            " [ 125  -61]\n",
            " [ -70   67]\n",
            " [ -16  -54]\n",
            " [ 121   49]\n",
            " [ -91   17]\n",
            " [   5 -101]\n",
            " [  29    7]\n",
            " [ -91  -36]\n",
            " [ -12  -25]\n",
            " [ 120  109]\n",
            " [  -7  -20]\n",
            " [  26   16]\n",
            " [  51  -63]\n",
            " [-106  -83]\n",
            " [ -58   56]\n",
            " [  -7   16]\n",
            " [ -95    1]\n",
            " [-102 -104]\n",
            " [  99  -68]\n",
            " [ 110   73]\n",
            " [ -36   90]\n",
            " [  97   -6]\n",
            " [ -82  -41]\n",
            " [  -8 -103]\n",
            " [  14 -101]\n",
            " [  32   66]\n",
            " [ -49   80]\n",
            " [ -64  -27]\n",
            " [ 127   58]]\n",
            "sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/Add <class 'numpy.int8'>\n",
            "Skipping tensor 'sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/Add' as it has null data.\n",
            "StatefulPartitionedCall_1:0_int8 <class 'numpy.int8'>\n",
            "[[96]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Set Classification Accuracy of 8-bit Model**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SZZ-Oth4nJOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test accuracy of quantized model\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Define the transformation function\n",
        "def convert_to_int8(X, y):\n",
        "    # Multiply by 255 and subtract 128 cast to int8\n",
        "    X = tf.cast((X * 255) - 128, tf.int8)\n",
        "    y = tf.cast((y * 255) - 128, tf.int8)\n",
        "    return X, y\n",
        "\n",
        "# Apply the transformation to the dataset\n",
        "test_dataset_quantized_inputs = test_dataset.map(convert_to_int8).unbatch()\n",
        "test_dataset_quantized_targets = []  # list to store ground truth NO2 concentration values for calculating R² Score & MAE\n",
        "predictions = []  # list to store predicted NO2 concentration values for calculating R² Score & MAE\n",
        "\n",
        "# Example: Inspect the first batch\n",
        "for X_batch, y_batch in test_dataset_quantized_inputs.take(1):\n",
        "    print(X_batch.numpy(), y_batch.numpy())\n",
        "for input, target in test_dataset_quantized_inputs.batch(1):\n",
        "    interpreter.set_tensor(input_details[0]['index'], input.numpy().astype('int8'))\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    predictions.append(int(output))\n",
        "    test_dataset_quantized_targets.append(int(target.numpy()))\n",
        "\n",
        "print(f\"Quantized Model Test Set MAE: {np.mean(np.abs(np.array(predictions) - test_dataset_quantized_targets))}\")\n",
        "print(f\"Quantized Model Test Set R² Score: {r2_score(test_dataset_quantized_targets, np.array(predictions))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSPokUuAfoOQ",
        "outputId": "81dcd6f6-c63b-4fa0-d73b-4570f1146b20"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-95 -31] -91\n",
            "Quantized Model Test Set MAE: 15.096385542168674\n",
            "Quantized Model Test Set R² Score: 0.8165994293630214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-884ca647e175>:27: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  predictions.append(int(output))\n",
            "<ipython-input-14-884ca647e175>:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  test_dataset_quantized_targets.append(int(target.numpy()))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the quantized TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Extract tensor details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "all_tensor_details = interpreter.get_tensor_details()\n",
        "\n",
        "# Extract weights, biases, scales, and zero points from allocated tensors\n",
        "quantized_params = {}\n",
        "for tensor in all_tensor_details:\n",
        "    # Check if the tensor has quantization parameters and valid data\n",
        "    try:\n",
        "        # Attempt to get tensor data\n",
        "        tensor_data = interpreter.get_tensor(tensor['index'])\n",
        "\n",
        "        if 'quantization_parameters' in tensor and tensor['quantization_parameters']['scales'].size > 0:\n",
        "            quantized_params[tensor['name']] = {\n",
        "                'values': tensor_data,\n",
        "                'scale': tensor['quantization_parameters']['scales'],\n",
        "                'zero_point': tensor['quantization_parameters']['zero_points']\n",
        "            }\n",
        "    except ValueError:\n",
        "        # Skip tensors with null data\n",
        "        if 'quantization_parameters' in tensor and tensor['quantization_parameters']['scales'].size > 0:\n",
        "            quantized_params[tensor['name']] = {\n",
        "                'scale': tensor['quantization_parameters']['scales'],\n",
        "                'zero_point': tensor['quantization_parameters']['zero_points']\n",
        "            }\n",
        "        print(f\"Skipping tensor '{tensor['name']}' as it has null data.\")\n",
        "\n",
        "print(\"Quantized parameters extracted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv4RuhPA3MDI",
        "outputId": "a76dcbdb-7772-4aa0-a0ed-7f07f8660d5f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping tensor 'sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/Add' as it has null data.\n",
            "Quantized parameters extracted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Print Names, Weights, Scales, and Zero Points of Quantized Model Tensors'**"
      ],
      "metadata": {
        "id": "V3QtTCSOe_8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, params in quantized_params.items():\n",
        "    print(f\"{name} - Scale: {params['scale']}, Zero Point: {params['zero_point']}\")\n",
        "    if 'values' in params:\n",
        "      print(params['values'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vO6T2gMerb9",
        "outputId": "d0f140ce-d922-475f-86aa-3aeb303e7d8d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "serving_default_keras_tensor:0_int8 - Scale: [0.00361139], Zero Point: [-128]\n",
            "[[0 0]]\n",
            "arith.constant - Scale: [0.00431388], Zero Point: [0]\n",
            "[[ 127   14   53   76   64 -106   52  -42  -85  -44  -55    3   33   28\n",
            "    10  -92   47   67  -70   12   55  124   21   91   48   71   -7  -57\n",
            "    33    6  -50   21]]\n",
            "sequential_1/dense_1_2/Add/ReadVariableOp - Scale: [1.2981408e-05], Zero Point: [0]\n",
            "[1006]\n",
            "sequential_1/dense_1/Add/ReadVariableOp - Scale: [1.37996485e-05], Zero Point: [0]\n",
            "[ 3679  -680     0  4065 -3252 10707   679  8886     0 -5100     0     0\n",
            "   517     0  -259 -1294     0 -1436 -2625  -354     0  3627   165   831\n",
            "   610     0     0     0   544    22     0   106]\n",
            "sequential_1/dense_1/MatMul - Scale: [0.00382115], Zero Point: [0]\n",
            "[[  98  -73]\n",
            " [  52  -11]\n",
            " [ -31  -52]\n",
            " [ 125  -61]\n",
            " [ -70   67]\n",
            " [ -16  -54]\n",
            " [ 121   49]\n",
            " [ -91   17]\n",
            " [   5 -101]\n",
            " [  29    7]\n",
            " [ -91  -36]\n",
            " [ -12  -25]\n",
            " [ 120  109]\n",
            " [  -7  -20]\n",
            " [  26   16]\n",
            " [  51  -63]\n",
            " [-106  -83]\n",
            " [ -58   56]\n",
            " [  -7   16]\n",
            " [ -95    1]\n",
            " [-102 -104]\n",
            " [  99  -68]\n",
            " [ 110   73]\n",
            " [ -36   90]\n",
            " [  97   -6]\n",
            " [ -82  -41]\n",
            " [  -8 -103]\n",
            " [  14 -101]\n",
            " [  32   66]\n",
            " [ -49   80]\n",
            " [ -64  -27]\n",
            " [ 127   58]]\n",
            "sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/Add - Scale: [0.00300922], Zero Point: [-128]\n",
            "StatefulPartitionedCall_1:0_int8 - Scale: [0.00306223], Zero Point: [-128]\n",
            "[[48]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Map TFLite Provided Names to Intuitive Ones**\n",
        "The TFLite Layer names after quantization are not very intuitive.\n",
        "Use the names above + the [Netron](https://netron.app/) application to update dictionary below so that it is very clear which layer is which. *You may need to update the names if any changes are made to the notebook.*"
      ],
      "metadata": {
        "id": "dDUXkdPJAlNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer name map\n",
        "layer_name_map = {\n",
        "    \"input_layer\": \"serving_default_keras_tensor:0_int8\",\n",
        "    \"layer_one_weights\": \"sequential_1/dense_1/MatMul\",\n",
        "    \"layer_one_bias\": \"sequential_1/dense_1/Add/ReadVariableOp\",\n",
        "    \"layer_one_output_activations\": \"sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/Add\",\n",
        "    \"layer_two_weights\": \"arith.constant\",\n",
        "    \"layer_two_bias\": \"sequential_1/dense_1_2/Add/ReadVariableOp\",\n",
        "    \"output_layer\": \"StatefulPartitionedCall_1:0_int8\"\n",
        "}"
      ],
      "metadata": {
        "id": "GqeYV9Ko_kAq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer_scale = quantized_params[layer_name_map[\"input_layer\"]][\"scale\"]\n",
        "input_layer_zero_point = quantized_params[layer_name_map[\"input_layer\"]][\"zero_point\"]\n",
        "\n",
        "layer_one_weights = quantized_params[layer_name_map[\"layer_one_weights\"]][\"values\"]\n",
        "layer_one_weights_scale = quantized_params[layer_name_map[\"layer_one_weights\"]][\"scale\"]\n",
        "layer_one_weights_zero_point = quantized_params[layer_name_map[\"layer_one_weights\"]][\"zero_point\"]\n",
        "layer_one_bias = quantized_params[layer_name_map[\"layer_one_bias\"]][\"values\"]\n",
        "\n",
        "layer_one_output_activations_scale = quantized_params[layer_name_map[\"layer_one_output_activations\"]][\"scale\"]\n",
        "layer_one_output_activations_zero_point = quantized_params[layer_name_map[\"layer_one_output_activations\"]][\"zero_point\"]\n",
        "\n",
        "layer_two_weights = quantized_params[layer_name_map[\"layer_two_weights\"]][\"values\"]\n",
        "layer_two_weights_scale = quantized_params[layer_name_map[\"layer_two_weights\"]][\"scale\"]\n",
        "layer_two_weights_zero_point = quantized_params[layer_name_map[\"layer_two_weights\"]][\"zero_point\"]\n",
        "layer_two_bias = quantized_params[layer_name_map[\"layer_two_bias\"]][\"values\"]\n",
        "\n",
        "output_layer_scale = quantized_params[layer_name_map[\"output_layer\"]][\"scale\"]\n",
        "output_layer_zero_point = quantized_params[layer_name_map[\"output_layer\"]][\"zero_point\"]"
      ],
      "metadata": {
        "id": "txvONXs98UfK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_fixed_point_multiplier(input_scale, weight_scale, output_scale):\n",
        "    # Calculate M0 and N from M = 2^-N M0 = (S1 * S2 / S3)\n",
        "    multiplier = input_scale * weight_scale / output_scale\n",
        "    shift = 0\n",
        "    while multiplier < 0.5:\n",
        "        multiplier *= 2\n",
        "        shift += 1\n",
        "    quantized_multiplier = multiplier * math.pow(2, 31)\n",
        "    return quantized_multiplier, shift"
      ],
      "metadata": {
        "id": "l00b5QnEaRmX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First layer requantization params\n",
        "layer_one_multiplier, layer_one_shift = calculate_fixed_point_multiplier(input_layer_scale, layer_one_weights_scale, layer_one_output_activations_scale)\n",
        "\n",
        "# Second layer requantization params\n",
        "layer_two_multiplier, layer_two_shift = calculate_fixed_point_multiplier(layer_one_output_activations_scale, layer_two_weights_scale, output_layer_scale)\n",
        "\n",
        "subscript_printing = str.maketrans(\"123456789\", \"₁₂₃₄₅₆₇₈₉\")\n",
        "print(\"Layer 1 Requantization Params:\")\n",
        "print(\"M01: \".translate(subscript_printing) + f\"{layer_one_multiplier[0]:.2f}\")\n",
        "print(\"N1: \".translate(subscript_printing)  + f\"{layer_one_shift}\")\n",
        "\n",
        "print(\"Layer 2 Requantization Params:\")\n",
        "print(\"M02: \".translate(subscript_printing) + f\"{layer_two_multiplier[0]:.2f}\")\n",
        "print(\"N2: \".translate(subscript_printing)  + f\"{layer_two_shift}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibGduAd2bMYE",
        "outputId": "58ac9a30-a7f6-45fa-c39c-a8fc084b405e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Requantization Params:\n",
            "M0₁: 1260531456.00\n",
            "N₁: 7\n",
            "Layer 2 Requantization Params:\n",
            "M0₂: 1165263744.00\n",
            "N₂: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Emulate 8-bit Integer Inference with Numpy**"
      ],
      "metadata": {
        "id": "pDmEYHIJoB5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create copy of test dataset\n",
        "TEST_SET_SIZE = 166\n",
        "test_dataset_copy = (iter(test_dataset_quantized_inputs.take(TEST_SET_SIZE)))"
      ],
      "metadata": {
        "id": "Sskn2QitsQ1e"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_tflite_golden_inference(tflite_model, inputs, debug=False):\n",
        "    #\n",
        "    # Golden Reference Implementation of TFLite Inference running on a single sample\n",
        "    #\n",
        "\n",
        "    # Add batch dim to single data sample\n",
        "    inputs = np.expand_dims(inputs, 0)\n",
        "\n",
        "    # Load TFLite model and allocate tensors\n",
        "    interpreter = tf.lite.Interpreter(model_content=tflite_model, experimental_preserve_all_tensors=True)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input and output tensors\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Load input tensor\n",
        "    interpreter.set_tensor(input_details[0]['index'], inputs)\n",
        "\n",
        "    # Run the model\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Print each layer's output if needed for verification\n",
        "    if debug:\n",
        "      print({\n",
        "          t['name']: interpreter.get_tensor(t['index'])\n",
        "          for t in interpreter.get_tensor_details()\n",
        "      })\n",
        "\n",
        "    return interpreter.get_tensor(output_details[0]['index'])"
      ],
      "metadata": {
        "id": "jja_F8B4sRqV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_numpy_inference(input):\n",
        "  #\n",
        "  # Numpy Reference Implementation of TFLite Inference running on a single sample\n",
        "  #\n",
        "\n",
        "  # (Inputs * Layer 1 Weights) + Bias followed by ReLU\n",
        "  x = np.matmul((input.numpy().astype(np.int32) - input_layer_zero_point.astype(np.int32)),(layer_one_weights.T.astype(np.int32) - layer_one_weights_zero_point.astype(np.int32)))\n",
        "  x = x + layer_one_bias\n",
        "  x = np.maximum(x, 0)\n",
        "\n",
        "  # Requantization pipeline\n",
        "  x = x * layer_one_multiplier\n",
        "  x = np.round((x / np.power(2,31))).astype(np.int32)\n",
        "  x = np.round((x / np.power(2, layer_one_shift))).astype(np.int32)\n",
        "  x = x + layer_one_output_activations_zero_point.astype(np.int32)\n",
        "  x = np.clip(x, -128, 127)\n",
        "\n",
        "  # (Layer 1 Activations * Layer 2 Weights) + Bias\n",
        "  x = np.matmul((x.astype(np.int32) - layer_one_output_activations_zero_point.astype(np.int32)), (layer_two_weights.T.astype(np.int32) - layer_two_weights_zero_point.astype(np.int32)))\n",
        "  x = x + layer_two_bias\n",
        "\n",
        "  # Requantization pipeline\n",
        "  x = x * layer_two_multiplier\n",
        "  x = np.round((x / np.power(2,31))).astype(np.int32)\n",
        "  x = np.round((x / np.power(2, layer_two_shift))).astype(np.int32)\n",
        "  x = x + output_layer_zero_point.astype(np.int32)\n",
        "  x = np.clip(x, -128, 127)\n",
        "\n",
        "  return x\n"
      ],
      "metadata": {
        "id": "5_Hx0jC7oBje"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_predictions = []\n",
        "numpy_predictions = []\n",
        "ground_truth = []\n",
        "\n",
        "for inputs, targets in test_dataset_copy:\n",
        "  tflite_output = run_tflite_golden_inference(tflite_quant_model, inputs.numpy().astype(np.int8))\n",
        "  numpy_output = run_numpy_inference(inputs)\n",
        "  tflite_predictions.append(int(tflite_output))\n",
        "  numpy_predictions.append(int(numpy_output))\n",
        "  ground_truth.append(int(targets.numpy()))\n",
        "  # Make sure that raw values of output tensors match exactly to validate numpy reference implementation\n",
        "  if np.array_equal(tflite_output.flatten()[0], numpy_output.flatten()):\n",
        "    print(tflite_output)\n",
        "    print(numpy_output)\n",
        "    print(\"ERROR: TFlite Golden Output Tensor does not match Numpy Implementation Output Tensor\")\n",
        "\n",
        "# Make sure accuracy is exactly the same to validate numpy implementation\n",
        "tflite_r2_score = r2_score(ground_truth, tflite_predictions)\n",
        "numpy_r2_score = r2_score(ground_truth, numpy_predictions)\n",
        "print(f\"TF Lite R² score: {tflite_r2_score}\")\n",
        "print(f\"Numpy R² score: {numpy_r2_score}\")\n",
        "print(\"Numpy Implementation matches TFLite Golden Implementation!\" if abs(tflite_r2_score - numpy_r2_score) <= 1e4 else \"Numpy Implementation does NOT match TFLite Golden Implementation!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1qDAzufb-ZD",
        "outputId": "78013588-15d9-472f-ab45-05d629a33fb4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-782384067832>:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  tflite_predictions.append(int(tflite_output))\n",
            "<ipython-input-24-782384067832>:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  numpy_predictions.append(int(numpy_output))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Lite R² score: 0.8164144775839145\n",
            "Numpy R² score: 0.8165725815241187\n",
            "Numpy Implementation matches TFLite Golden Implementation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Write Test Set Data to CSV for C Implementation in Flexibench Repository**"
      ],
      "metadata": {
        "id": "baAWcWzjEK5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dump_test_data_to_csv(dataset, headers, filename):\n",
        "  with open(filename, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(headers)\n",
        "    tflite_predictions = []\n",
        "    ground_truth = []\n",
        "    for inputs, targets in dataset:\n",
        "      # Write the original TFLite model prediction along with inputs and ground truth label to the CSV for reference\n",
        "      tflite_model_output = run_tflite_golden_inference(tflite_quant_model, inputs)\n",
        "      tflite_predictions.append(int(tflite_model_output))\n",
        "      ground_truth.append(int(targets.numpy()))\n",
        "      writer = csv.writer(csvfile)\n",
        "      writer.writerow(np.append(inputs.numpy(), [int(tflite_model_output), targets.numpy()]))\n",
        "    print(f\"TF Lite R² score: {r2_score(ground_truth, tflite_predictions)}\")\n",
        "    print(\"CSV saved.\")\n",
        "\n",
        "column_names = ['CO(GT)'] + ['NO2(GT)'] + ['TFLite_Model_Prediction'] + ['NOx(GT)_Golden_Label']\n",
        "dataset_copy_for_csv = iter(test_dataset_quantized_inputs.take(TEST_SET_SIZE))\n",
        "dump_test_data_to_csv(dataset_copy_for_csv, column_names, 'samples.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fp2rAmNG_dFh",
        "outputId": "579cbd38-18af-410c-85ef-dda76ec2f3db"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-dde715989c1c>:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  tflite_predictions.append(int(tflite_model_output))\n",
            "<ipython-input-25-dde715989c1c>:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  writer.writerow(np.append(inputs.numpy(), [int(tflite_model_output), targets.numpy()]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Lite R² score: 0.8164144775839145\n",
            "CSV saved.\n"
          ]
        }
      ]
    }
  ]
}